{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MergeDates.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP/+EbiUECgHTGezglnE2BW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XGHouFTW/py-cryptopredict/blob/main/MergeDates.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "e7ozAkhLm43n"
      },
      "outputs": [],
      "source": [
        "# This script takes in a list of datasets, averages the data values by day, then\n",
        "# Appends the averages into the dataset, creating a new column each time\n",
        "# INPUTS: Crypto price dataset, datasets to average\n",
        "# OUTPUTS: One dataset, with all columns, averaged by day\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import sys\n",
        "\n",
        "def main(out_file: str, filenames: list, base: pd.DataFrame):\n",
        "  for filename in filenames:\n",
        "    dataset = pd.read_csv(filename)\n",
        "    base = pd.concat([base, average_by_day(dataset)], axis=1)\n",
        "  base.to_csv(out_file, index=False)\n",
        "\n",
        "def average_by_day(df: pd.DataFrame, start_date: datetime.date, end_date: datetime.date)-> pd.DataFrame:\n",
        "  # return daily averages of a dataset (rows with identical dates are averaged \n",
        "  # and consolidated into one row)\n",
        "  averaged_df = pd.DataFrame(np.zeros((800, len(list(df.columns)))), columns = df.columns)\n",
        "  current_date = start_date\n",
        "  time_step = datetime.timedelta(days=1)\n",
        "  while current_date <= end_date:\n",
        "    day_average = calculate_average(current_date, df)\n",
        "    averaged_df = pd.concat([averaged_df, day_average], axis=0)\n",
        "    current_date = current_date + time_step\n",
        "  return averaged_df\n",
        "\n",
        "def calculate_average(date: datetime.date, df: pd.DataFrame):\n",
        "  daily_data = df[df[\"Date\"]==date]\n",
        "  averages = pd.DataFrame([np.mean(daily_data[column]) for column in list(df.columns)], columns = df.columns)\n",
        "  return averages"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  filepath = \"./\"\n",
        "  out_file = filepath + \"merged_data.csv\"\n",
        "  filenames = [\"NASDAQ_historical.csv\", \"AMC_historical.csv\", \"GME_historical.csv\", \n",
        "               \"TSLA_historical.csv\", \"DJI_historical.csv\", \"S&P_historical.csv\", \n",
        "               \"AAPL_historical.csv\", \"reddit-bitcoin.csv\", \"reddit-finance.csv\", \n",
        "               \"reddit-politics.csv\", \"reddit-economy.csv\", \"reddit-cryptocurrency.csv\", \n",
        "               \"reddit-pandemic.csv\", \"reddit-dogecoin.csv\", \"reddit-ethereum.csv\", \n",
        "               \"pandemic_news_scored.csv\", \"politics_news_scored.csv\", \n",
        "               \"finance_news_scored.csv\", \"economy_news_scored.csv\", \n",
        "               \"dogecoin_news_scored.csv\", \"bitcoin_news_scored.csv\", \n",
        "               \"ethereum_news_scored.csv\", \"cryptocurrency_news_scored.csv\"]\n",
        "  "
      ],
      "metadata": {
        "id": "u3V7KEHH0KIl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
