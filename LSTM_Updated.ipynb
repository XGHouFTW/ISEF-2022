{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XGHouFTW/py-cryptopredict/blob/main/LSTM_Updated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gS2OkcDNB6Ds",
        "outputId": "e6d0a6a3-59d2-4a52-b305-37b43a9bab55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/MyDrive\n",
            "                   Date  BTC-ChangeFactor  ETH-ChangeFactor  \\\n",
            "0    2020-01-31 0:00:00          0.983406          0.975226   \n",
            "1    2020-02-01 0:00:00          1.004977          1.019766   \n",
            "2    2020-02-02 0:00:00          0.995159          1.027706   \n",
            "3    2020-02-03 0:00:00          0.994525          1.006668   \n",
            "4    2020-02-04 0:00:00          0.987961          0.996781   \n",
            "..                  ...               ...               ...   \n",
            "727  2022-01-27 0:00:00          1.008044          0.982090   \n",
            "728  2022-01-28 0:00:00          1.017665          1.051802   \n",
            "729  2022-01-29 0:00:00          1.009462          1.019828   \n",
            "730  2022-01-30 0:00:00          0.993858          1.001886   \n",
            "731  2022-01-31 0:00:00          1.014843          1.032657   \n",
            "\n",
            "     DOGE-ChangeFactor  BTC-Open-EMA7  BTC-High-EMA7  BTC-Low-EMA7  \\\n",
            "0             0.981148    9508.313477    9521.706055   9230.776367   \n",
            "1             1.012965    9467.824463    9501.110352   9251.392090   \n",
            "2             1.019413    9448.323426    9493.032227   9243.000122   \n",
            "3             0.989457    9422.413468    9504.867188   9244.408539   \n",
            "4             1.026661    9390.020550    9461.466797   9211.509285   \n",
            "..                 ...            ...            ...           ...   \n",
            "727           0.982547   37538.862062   38409.071774  36182.259659   \n",
            "728           1.002917   37436.257874   38295.023558  36189.472089   \n",
            "729           1.009933   37522.372115   38365.333099  36493.722232   \n",
            "730           0.974933   37679.758579   38340.584784  36729.719409   \n",
            "731           1.016749   37739.889247   38417.254018  36730.683112   \n",
            "\n",
            "     BTC-Close-EMA7  BTC-Adj Close-EMA7  BTC-Volume-EMA7  ...  \\\n",
            "0       9350.529297         9350.529297     2.943249e+10  ...   \n",
            "1       9361.115723         9361.115723     2.855503e+10  ...   \n",
            "2       9356.928101         9356.928101     2.912521e+10  ...   \n",
            "3       9341.076446         9341.076446     2.957743e+10  ...   \n",
            "4       9301.048058         9301.048058     2.965637e+10  ...   \n",
            "..              ...                 ...              ...  ...   \n",
            "727    37438.848769        37438.848769     2.970680e+10  ...   \n",
            "728    37525.219584        37525.219584     2.783981e+10  ...   \n",
            "729    37678.459611        37678.459611     2.517840e+10  ...   \n",
            "730    37738.245098        37738.245098     2.254469e+10  ...   \n",
            "731    37924.465073        37924.465073     2.209220e+10  ...   \n",
            "\n",
            "     reddit-politicsNegScoreaverage-EMA7  reddit-politicsComScoresum-EMA7  \\\n",
            "0                               0.108745                        80.578000   \n",
            "1                               0.111572                        68.481725   \n",
            "2                               0.112800                        65.678469   \n",
            "3                               0.112592                        64.871752   \n",
            "4                               0.111291                        70.378914   \n",
            "..                                   ...                              ...   \n",
            "727                             0.124408                       -19.565339   \n",
            "728                             0.119889                        -5.280304   \n",
            "729                             0.120921                       -11.116853   \n",
            "730                             0.124151                       -15.809690   \n",
            "731                             0.130193                       -30.823117   \n",
            "\n",
            "     reddit-politicsComScoreaverage-EMA7  reddit-politicsScorecount-EMA7  \\\n",
            "0                               0.097199                      829.000000   \n",
            "1                               0.084283                      798.500000   \n",
            "2                               0.084236                      769.125000   \n",
            "3                               0.084361                      761.093750   \n",
            "4                               0.089830                      775.320312   \n",
            "..                                   ...                             ...   \n",
            "727                            -0.037122                      527.671820   \n",
            "728                            -0.010824                      533.753865   \n",
            "729                            -0.021907                      530.065399   \n",
            "730                            -0.033451                      507.299049   \n",
            "731                            -0.062349                      507.724287   \n",
            "\n",
            "     BTC-ChangeFactor-EMA7-prediction  ETH-ChangeFactor-EMA7-prediction  \\\n",
            "0                            0.000000                          0.000000   \n",
            "1                            0.000000                          0.000000   \n",
            "2                            0.000000                          0.000000   \n",
            "3                            0.000000                          0.000000   \n",
            "4                            0.000000                          0.000000   \n",
            "..                                ...                               ...   \n",
            "727                          0.997156                          0.943944   \n",
            "728                          0.997156                          0.943783   \n",
            "729                          0.997156                          0.943779   \n",
            "730                          0.997156                          0.939972   \n",
            "731                               NaN                          0.000000   \n",
            "\n",
            "     DOGE-ChangeFactor-EMA7-prediction  BTC-ChangeFactor-prediction  \\\n",
            "0                             0.000000                     0.000000   \n",
            "1                             0.000000                     0.000000   \n",
            "2                             0.000000                     0.000000   \n",
            "3                             0.000000                     0.000000   \n",
            "4                             0.000000                     0.000000   \n",
            "..                                 ...                          ...   \n",
            "727                           1.045349                     1.011986   \n",
            "728                           1.045351                     1.011986   \n",
            "729                           1.045351                     1.011986   \n",
            "730                           1.047855                     1.011986   \n",
            "731                           0.000000                     0.000000   \n",
            "\n",
            "     ETH-ChangeFactor-prediction  DOGE-ChangeFactor-prediction  \n",
            "0                       0.000000                      0.000000  \n",
            "1                       0.000000                      0.000000  \n",
            "2                       0.000000                      0.000000  \n",
            "3                       0.000000                      0.000000  \n",
            "4                       0.000000                      0.000000  \n",
            "..                           ...                           ...  \n",
            "727                     1.004704                      1.014224  \n",
            "728                     1.005917                      1.012282  \n",
            "729                     1.006684                      1.013887  \n",
            "730                     1.006806                      1.024218  \n",
            "731                     0.000000                      0.000000  \n",
            "\n",
            "[732 rows x 192 columns]\n",
            "Total number of days present in the dataset:  732\n",
            "Total number of fields present in the dataset:  192\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 732 entries, 0 to 731\n",
            "Columns: 192 entries, Date to DOGE-ChangeFactor-prediction\n",
            "dtypes: float64(191), object(1)\n",
            "memory usage: 1.1+ MB\n",
            "(732, 192)                  Date  BTC-ChangeFactor  ETH-ChangeFactor  DOGE-ChangeFactor  \\\n",
            "0  2020-01-31 0:00:00          0.983406          0.975226           0.981148   \n",
            "1  2020-02-01 0:00:00          1.004977          1.019766           1.012965   \n",
            "2  2020-02-02 0:00:00          0.995159          1.027706           1.019413   \n",
            "3  2020-02-03 0:00:00          0.994525          1.006668           0.989457   \n",
            "4  2020-02-04 0:00:00          0.987961          0.996781           1.026661   \n",
            "\n",
            "   BTC-Open-EMA7  BTC-High-EMA7  BTC-Low-EMA7  BTC-Close-EMA7  \\\n",
            "0    9508.313477    9521.706055   9230.776367     9350.529297   \n",
            "1    9467.824463    9501.110352   9251.392090     9361.115723   \n",
            "2    9448.323426    9493.032227   9243.000122     9356.928101   \n",
            "3    9422.413468    9504.867188   9244.408539     9341.076446   \n",
            "4    9390.020550    9461.466797   9211.509285     9301.048058   \n",
            "\n",
            "   BTC-Adj Close-EMA7  BTC-Volume-EMA7  ...  \\\n",
            "0         9350.529297     2.943249e+10  ...   \n",
            "1         9361.115723     2.855503e+10  ...   \n",
            "2         9356.928101     2.912521e+10  ...   \n",
            "3         9341.076446     2.957743e+10  ...   \n",
            "4         9301.048058     2.965637e+10  ...   \n",
            "\n",
            "   reddit-politicsNegScoreaverage-EMA7  reddit-politicsComScoresum-EMA7  \\\n",
            "0                             0.108745                        80.578000   \n",
            "1                             0.111572                        68.481725   \n",
            "2                             0.112800                        65.678469   \n",
            "3                             0.112592                        64.871752   \n",
            "4                             0.111291                        70.378914   \n",
            "\n",
            "   reddit-politicsComScoreaverage-EMA7  reddit-politicsScorecount-EMA7  \\\n",
            "0                             0.097199                      829.000000   \n",
            "1                             0.084283                      798.500000   \n",
            "2                             0.084236                      769.125000   \n",
            "3                             0.084361                      761.093750   \n",
            "4                             0.089830                      775.320312   \n",
            "\n",
            "   BTC-ChangeFactor-EMA7-prediction  ETH-ChangeFactor-EMA7-prediction  \\\n",
            "0                               0.0                               0.0   \n",
            "1                               0.0                               0.0   \n",
            "2                               0.0                               0.0   \n",
            "3                               0.0                               0.0   \n",
            "4                               0.0                               0.0   \n",
            "\n",
            "   DOGE-ChangeFactor-EMA7-prediction  BTC-ChangeFactor-prediction  \\\n",
            "0                                0.0                          0.0   \n",
            "1                                0.0                          0.0   \n",
            "2                                0.0                          0.0   \n",
            "3                                0.0                          0.0   \n",
            "4                                0.0                          0.0   \n",
            "\n",
            "   ETH-ChangeFactor-prediction  DOGE-ChangeFactor-prediction  \n",
            "0                          0.0                           0.0  \n",
            "1                          0.0                           0.0  \n",
            "2                          0.0                           0.0  \n",
            "3                          0.0                           0.0  \n",
            "4                          0.0                           0.0  \n",
            "\n",
            "[5 rows x 192 columns]                    Date  BTC-ChangeFactor  ETH-ChangeFactor  \\\n",
            "727  2022-01-27 0:00:00          1.008044          0.982090   \n",
            "728  2022-01-28 0:00:00          1.017665          1.051802   \n",
            "729  2022-01-29 0:00:00          1.009462          1.019828   \n",
            "730  2022-01-30 0:00:00          0.993858          1.001886   \n",
            "731  2022-01-31 0:00:00          1.014843          1.032657   \n",
            "\n",
            "     DOGE-ChangeFactor  BTC-Open-EMA7  BTC-High-EMA7  BTC-Low-EMA7  \\\n",
            "727           0.982547   37538.862062   38409.071774  36182.259659   \n",
            "728           1.002917   37436.257874   38295.023558  36189.472089   \n",
            "729           1.009933   37522.372115   38365.333099  36493.722232   \n",
            "730           0.974933   37679.758579   38340.584784  36729.719409   \n",
            "731           1.016749   37739.889247   38417.254018  36730.683112   \n",
            "\n",
            "     BTC-Close-EMA7  BTC-Adj Close-EMA7  BTC-Volume-EMA7  ...  \\\n",
            "727    37438.848769        37438.848769     2.970680e+10  ...   \n",
            "728    37525.219584        37525.219584     2.783981e+10  ...   \n",
            "729    37678.459611        37678.459611     2.517840e+10  ...   \n",
            "730    37738.245098        37738.245098     2.254469e+10  ...   \n",
            "731    37924.465073        37924.465073     2.209220e+10  ...   \n",
            "\n",
            "     reddit-politicsNegScoreaverage-EMA7  reddit-politicsComScoresum-EMA7  \\\n",
            "727                             0.124408                       -19.565339   \n",
            "728                             0.119889                        -5.280304   \n",
            "729                             0.120921                       -11.116853   \n",
            "730                             0.124151                       -15.809690   \n",
            "731                             0.130193                       -30.823117   \n",
            "\n",
            "     reddit-politicsComScoreaverage-EMA7  reddit-politicsScorecount-EMA7  \\\n",
            "727                            -0.037122                      527.671820   \n",
            "728                            -0.010824                      533.753865   \n",
            "729                            -0.021907                      530.065399   \n",
            "730                            -0.033451                      507.299049   \n",
            "731                            -0.062349                      507.724287   \n",
            "\n",
            "     BTC-ChangeFactor-EMA7-prediction  ETH-ChangeFactor-EMA7-prediction  \\\n",
            "727                          0.997156                          0.943944   \n",
            "728                          0.997156                          0.943783   \n",
            "729                          0.997156                          0.943779   \n",
            "730                          0.997156                          0.939972   \n",
            "731                               NaN                          0.000000   \n",
            "\n",
            "     DOGE-ChangeFactor-EMA7-prediction  BTC-ChangeFactor-prediction  \\\n",
            "727                           1.045349                     1.011986   \n",
            "728                           1.045351                     1.011986   \n",
            "729                           1.045351                     1.011986   \n",
            "730                           1.047855                     1.011986   \n",
            "731                           0.000000                     0.000000   \n",
            "\n",
            "     ETH-ChangeFactor-prediction  DOGE-ChangeFactor-prediction  \n",
            "727                     1.004704                      1.014224  \n",
            "728                     1.005917                      1.012282  \n",
            "729                     1.006684                      1.013887  \n",
            "730                     1.006806                      1.024218  \n",
            "731                     0.000000                      0.000000  \n",
            "\n",
            "[5 rows x 192 columns] None        BTC-ChangeFactor  ETH-ChangeFactor  DOGE-ChangeFactor  BTC-Open-EMA7  \\\n",
            "count        732.000000        732.000000         732.000000     732.000000   \n",
            "mean           1.002595          1.004976           1.011812   30461.602130   \n",
            "std            0.039927          0.053058           0.159947   19298.614209   \n",
            "min            0.628131          0.576911           0.602013    5630.800467   \n",
            "25%            0.985045          0.979477           0.975170   10417.215838   \n",
            "50%            1.002175          1.005111           1.000294   33590.641511   \n",
            "75%            1.020434          1.032652           1.019834   48079.111695   \n",
            "max            1.187972          1.259513           4.556075   64732.440897   \n",
            "\n",
            "       BTC-High-EMA7  BTC-Low-EMA7  BTC-Close-EMA7  BTC-Adj Close-EMA7  \\\n",
            "count     732.000000    732.000000      732.000000          732.000000   \n",
            "mean    31282.642561  29539.617602    30493.419400        30493.419400   \n",
            "std     19818.336396  18677.398698    19278.783862        19278.783862   \n",
            "min      5988.586282   5312.103421     5628.406731         5628.406731   \n",
            "25%     10582.725400  10205.094045    10418.403745        10418.403745   \n",
            "50%     34850.385181  32282.329801    33712.547414        33712.547414   \n",
            "75%     49212.903934  46885.806900    48125.596625        48125.596625   \n",
            "max     66053.493214  63268.913095    64733.556249        64733.556249   \n",
            "\n",
            "       BTC-Volume-EMA7  BTC-ChangeFactor-EMA7  ...  \\\n",
            "count     7.320000e+02             732.000000  ...   \n",
            "mean      4.019252e+10               1.002506  ...   \n",
            "std       1.594814e+10               0.014912  ...   \n",
            "min       1.417846e+10               0.897097  ...   \n",
            "25%       3.060710e+10               0.994403  ...   \n",
            "50%       3.658683e+10               1.002786  ...   \n",
            "75%       4.558993e+10               1.010813  ...   \n",
            "max       1.407464e+11               1.057723  ...   \n",
            "\n",
            "       reddit-politicsNegScoreaverage-EMA7  reddit-politicsComScoresum-EMA7  \\\n",
            "count                           732.000000                       732.000000   \n",
            "mean                              0.121619                        -7.765434   \n",
            "std                               0.006025                        33.522447   \n",
            "min                               0.105313                      -105.649245   \n",
            "25%                               0.117829                       -28.366292   \n",
            "50%                               0.121418                       -11.005474   \n",
            "75%                               0.125174                         6.741266   \n",
            "max                               0.145591                       114.508326   \n",
            "\n",
            "       reddit-politicsComScoreaverage-EMA7  reddit-politicsScorecount-EMA7  \\\n",
            "count                           732.000000                      732.000000   \n",
            "mean                             -0.018201                      600.078999   \n",
            "std                               0.050592                      113.758005   \n",
            "min                              -0.156466                       38.787349   \n",
            "25%                              -0.054559                      527.573614   \n",
            "50%                              -0.022107                      615.908654   \n",
            "75%                               0.009018                      674.090313   \n",
            "max                               0.145453                      829.000000   \n",
            "\n",
            "       BTC-ChangeFactor-EMA7-prediction  ETH-ChangeFactor-EMA7-prediction  \\\n",
            "count                        731.000000                        732.000000   \n",
            "mean                           0.972347                          0.949841   \n",
            "std                            0.144712                          0.147185   \n",
            "min                            0.000000                          0.000000   \n",
            "25%                            0.996000                          0.940987   \n",
            "50%                            0.999329                          0.956949   \n",
            "75%                            1.005287                          1.008711   \n",
            "max                            1.021075                          1.026691   \n",
            "\n",
            "       DOGE-ChangeFactor-EMA7-prediction  BTC-ChangeFactor-prediction  \\\n",
            "count                         732.000000                   732.000000   \n",
            "mean                            1.018250                     0.982035   \n",
            "std                             0.153712                     0.153849   \n",
            "min                             0.000000                     0.000000   \n",
            "25%                             1.030381                     1.010873   \n",
            "50%                             1.042920                     1.015207   \n",
            "75%                             1.053955                     1.016682   \n",
            "max                             1.117330                     1.076745   \n",
            "\n",
            "       ETH-ChangeFactor-prediction  DOGE-ChangeFactor-prediction  \n",
            "count                   732.000000                    732.000000  \n",
            "mean                      0.990970                      0.986437  \n",
            "std                       0.149306                      0.152403  \n",
            "min                       0.000000                      0.000000  \n",
            "25%                       1.000491                      0.991664  \n",
            "50%                       1.010035                      1.018397  \n",
            "75%                       1.024957                      1.034497  \n",
            "max                       1.064733                      1.081838  \n",
            "\n",
            "[8 rows x 191 columns] Index(['Date', 'BTC-ChangeFactor', 'ETH-ChangeFactor', 'DOGE-ChangeFactor',\n",
            "       'BTC-Open-EMA7', 'BTC-High-EMA7', 'BTC-Low-EMA7', 'BTC-Close-EMA7',\n",
            "       'BTC-Adj Close-EMA7', 'BTC-Volume-EMA7',\n",
            "       ...\n",
            "       'reddit-politicsNegScoreaverage-EMA7',\n",
            "       'reddit-politicsComScoresum-EMA7',\n",
            "       'reddit-politicsComScoreaverage-EMA7', 'reddit-politicsScorecount-EMA7',\n",
            "       'BTC-ChangeFactor-EMA7-prediction', 'ETH-ChangeFactor-EMA7-prediction',\n",
            "       'DOGE-ChangeFactor-EMA7-prediction', 'BTC-ChangeFactor-prediction',\n",
            "       'ETH-ChangeFactor-prediction', 'DOGE-ChangeFactor-prediction'],\n",
            "      dtype='object', length=192)\n",
            "\n",
            "\n",
            "\n",
            "Null Values: 1\n",
            "\n",
            "\n",
            "\n",
            "NA values: True \n",
            "\n",
            "\n",
            "\n",
            "(732, 192)\n",
            "(716, 15, 191) (716,)\n",
            "Epoch 1/200\n",
            "18/18 [==============================] - 4s 70ms/step - loss: 1.5974 - accuracy: 0.0000e+00 - val_loss: 0.9257 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.6225 - accuracy: 0.0000e+00 - val_loss: 0.2561 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.3256 - accuracy: 0.0000e+00 - val_loss: 0.0659 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.2493 - accuracy: 0.0000e+00 - val_loss: 0.0339 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.2192 - accuracy: 0.0000e+00 - val_loss: 0.0321 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.2242 - accuracy: 0.0000e+00 - val_loss: 0.0308 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.2140 - accuracy: 0.0000e+00 - val_loss: 0.0287 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/200\n",
            "18/18 [==============================] - 1s 79ms/step - loss: 0.1920 - accuracy: 0.0000e+00 - val_loss: 0.0277 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/200\n",
            "18/18 [==============================] - 2s 101ms/step - loss: 0.2015 - accuracy: 0.0000e+00 - val_loss: 0.0242 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/200\n",
            "18/18 [==============================] - 2s 103ms/step - loss: 0.1672 - accuracy: 0.0000e+00 - val_loss: 0.0224 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/200\n",
            "18/18 [==============================] - 2s 95ms/step - loss: 0.1609 - accuracy: 0.0000e+00 - val_loss: 0.0226 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1657 - accuracy: 0.0000e+00 - val_loss: 0.0213 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.1606 - accuracy: 0.0000e+00 - val_loss: 0.0185 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1474 - accuracy: 0.0000e+00 - val_loss: 0.0172 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.1465 - accuracy: 0.0000e+00 - val_loss: 0.0169 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.1310 - accuracy: 0.0000e+00 - val_loss: 0.0162 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1110 - accuracy: 0.0000e+00 - val_loss: 0.0150 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0900 - accuracy: 0.0000e+00 - val_loss: 0.0143 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.1015 - accuracy: 0.0000e+00 - val_loss: 0.0139 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0989 - accuracy: 0.0000e+00 - val_loss: 0.0133 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0885 - accuracy: 0.0000e+00 - val_loss: 0.0128 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0764 - accuracy: 0.0000e+00 - val_loss: 0.0124 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0672 - accuracy: 0.0000e+00 - val_loss: 0.0119 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0890 - accuracy: 0.0000e+00 - val_loss: 0.0113 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0654 - accuracy: 0.0000e+00 - val_loss: 0.0108 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0683 - accuracy: 0.0000e+00 - val_loss: 0.0108 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0607 - accuracy: 0.0000e+00 - val_loss: 0.0106 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0569 - accuracy: 0.0000e+00 - val_loss: 0.0100 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0598 - accuracy: 0.0000e+00 - val_loss: 0.0098 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0509 - accuracy: 0.0000e+00 - val_loss: 0.0094 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0470 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0516 - accuracy: 0.0000e+00 - val_loss: 0.0085 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0592 - accuracy: 0.0000e+00 - val_loss: 0.0085 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0496 - accuracy: 0.0000e+00 - val_loss: 0.0082 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0463 - accuracy: 0.0000e+00 - val_loss: 0.0083 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0449 - accuracy: 0.0000e+00 - val_loss: 0.0078 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0416 - accuracy: 0.0000e+00 - val_loss: 0.0075 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0389 - accuracy: 0.0000e+00 - val_loss: 0.0072 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0335 - accuracy: 0.0000e+00 - val_loss: 0.0073 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0359 - accuracy: 0.0000e+00 - val_loss: 0.0071 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0344 - accuracy: 0.0000e+00 - val_loss: 0.0071 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0348 - accuracy: 0.0000e+00 - val_loss: 0.0073 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0353 - accuracy: 0.0000e+00 - val_loss: 0.0077 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0334 - accuracy: 0.0000e+00 - val_loss: 0.0072 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0336 - accuracy: 0.0000e+00 - val_loss: 0.0070 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0267 - accuracy: 0.0000e+00 - val_loss: 0.0064 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0257 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0245 - accuracy: 0.0000e+00 - val_loss: 0.0067 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/200\n",
            "18/18 [==============================] - 1s 45ms/step - loss: 0.0228 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0260 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0263 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0236 - accuracy: 0.0000e+00 - val_loss: 0.0062 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0238 - accuracy: 0.0000e+00 - val_loss: 0.0052 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0219 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0214 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0217 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0168 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0194 - accuracy: 0.0000e+00 - val_loss: 0.0051 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0183 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0190 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0191 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0181 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0170 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0154 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0148 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0163 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0135 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0121 - accuracy: 0.0000e+00 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0143 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0150 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0139 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0112 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0125 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0134 - accuracy: 0.0000e+00 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0111 - accuracy: 0.0000e+00 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0108 - accuracy: 0.0000e+00 - val_loss: 0.0022 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0102 - accuracy: 0.0000e+00 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0122 - accuracy: 0.0000e+00 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0112 - accuracy: 0.0000e+00 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0117 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 81/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0115 - accuracy: 0.0000e+00 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0110 - accuracy: 0.0000e+00 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 86/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0090 - accuracy: 0.0000e+00 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0089 - accuracy: 0.0000e+00 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0077 - accuracy: 0.0000e+00 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 92/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0066 - accuracy: 0.0000e+00 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0073 - accuracy: 0.0000e+00 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/200\n",
            "18/18 [==============================] - 1s 80ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0061 - accuracy: 0.0000e+00 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/200\n",
            "18/18 [==============================] - 1s 45ms/step - loss: 0.0071 - accuracy: 0.0000e+00 - val_loss: 9.5529e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 97/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0079 - accuracy: 0.0000e+00 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 98/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0065 - accuracy: 0.0000e+00 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0072 - accuracy: 0.0000e+00 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 100/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0076 - accuracy: 0.0000e+00 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 101/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0063 - accuracy: 0.0000e+00 - val_loss: 8.4980e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 102/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0053 - accuracy: 0.0000e+00 - val_loss: 8.5001e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 103/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0063 - accuracy: 0.0000e+00 - val_loss: 7.6221e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 104/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0054 - accuracy: 0.0000e+00 - val_loss: 7.0379e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 105/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0059 - accuracy: 0.0000e+00 - val_loss: 7.3518e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 106/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0077 - accuracy: 0.0000e+00 - val_loss: 7.6520e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 107/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0068 - accuracy: 0.0000e+00 - val_loss: 9.7854e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 108/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0058 - accuracy: 0.0000e+00 - val_loss: 8.5313e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 109/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0058 - accuracy: 0.0000e+00 - val_loss: 6.9119e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 110/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 7.0417e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 111/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 8.1748e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 112/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0058 - accuracy: 0.0000e+00 - val_loss: 7.1816e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 113/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0051 - accuracy: 0.0000e+00 - val_loss: 6.2959e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 114/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0067 - accuracy: 0.0000e+00 - val_loss: 7.1254e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 115/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 6.3073e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 116/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0058 - accuracy: 0.0000e+00 - val_loss: 5.7447e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 117/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0051 - accuracy: 0.0000e+00 - val_loss: 6.6595e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 118/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 5.7214e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 119/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0054 - accuracy: 0.0000e+00 - val_loss: 5.1051e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 120/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 6.5477e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 121/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 5.5364e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 122/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 5.4170e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 123/200\n",
            "18/18 [==============================] - 1s 53ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 6.0278e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 124/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0052 - accuracy: 0.0000e+00 - val_loss: 4.8245e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 125/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 6.6651e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 126/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 5.0797e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 127/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 8.7406e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 128/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 4.4741e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 129/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 6.5338e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 130/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 4.4817e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 131/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 5.7283e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 132/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 3.7548e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 133/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 4.2885e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 134/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 3.3667e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 135/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 3.1792e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 136/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 2.9405e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 137/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 3.8186e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 138/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 3.0504e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 139/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 2.9083e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 140/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 3.7350e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 141/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 3.5475e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 142/200\n",
            "18/18 [==============================] - 1s 53ms/step - loss: 0.0032 - accuracy: 0.0000e+00 - val_loss: 2.8884e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 143/200\n",
            "18/18 [==============================] - 1s 53ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 2.9039e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 144/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0034 - accuracy: 0.0000e+00 - val_loss: 3.0343e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 145/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0034 - accuracy: 0.0000e+00 - val_loss: 2.9196e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 146/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 2.9077e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 147/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 3.7870e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 148/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 2.7272e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 149/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 3.1394e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 150/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 3.7338e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 151/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0033 - accuracy: 0.0000e+00 - val_loss: 2.5944e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 152/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 2.5037e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 153/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0027 - accuracy: 0.0000e+00 - val_loss: 2.4082e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 154/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 3.3336e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 155/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0032 - accuracy: 0.0000e+00 - val_loss: 2.6004e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 156/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0029 - accuracy: 0.0000e+00 - val_loss: 2.5844e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 157/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0030 - accuracy: 0.0000e+00 - val_loss: 2.3720e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 158/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0029 - accuracy: 0.0000e+00 - val_loss: 2.9658e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 159/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0029 - accuracy: 0.0000e+00 - val_loss: 4.2332e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 160/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0033 - accuracy: 0.0000e+00 - val_loss: 2.2579e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 161/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0027 - accuracy: 0.0000e+00 - val_loss: 2.3160e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 162/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 2.3548e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 163/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0025 - accuracy: 0.0000e+00 - val_loss: 2.7742e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 164/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0027 - accuracy: 0.0000e+00 - val_loss: 2.3922e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 165/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0034 - accuracy: 0.0000e+00 - val_loss: 3.1937e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 166/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 2.4088e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 167/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 2.2318e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 168/200\n",
            "18/18 [==============================] - 1s 52ms/step - loss: 0.0033 - accuracy: 0.0000e+00 - val_loss: 2.2838e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 169/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0033 - accuracy: 0.0000e+00 - val_loss: 2.4127e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 170/200\n",
            "18/18 [==============================] - 1s 52ms/step - loss: 0.0027 - accuracy: 0.0000e+00 - val_loss: 2.3248e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 171/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 2.5960e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 172/200\n",
            "18/18 [==============================] - 1s 52ms/step - loss: 0.0030 - accuracy: 0.0000e+00 - val_loss: 2.4079e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 173/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0025 - accuracy: 0.0000e+00 - val_loss: 3.2759e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 174/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0027 - accuracy: 0.0000e+00 - val_loss: 2.5240e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 175/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 2.7136e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 176/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0026 - accuracy: 0.0000e+00 - val_loss: 2.1266e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 177/200\n",
            "18/18 [==============================] - 1s 52ms/step - loss: 0.0026 - accuracy: 0.0000e+00 - val_loss: 2.3292e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 178/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0034 - accuracy: 0.0000e+00 - val_loss: 2.4007e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 179/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0027 - accuracy: 0.0000e+00 - val_loss: 1.9675e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 180/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0030 - accuracy: 0.0000e+00 - val_loss: 2.1909e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 181/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0026 - accuracy: 0.0000e+00 - val_loss: 5.0092e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 182/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0028 - accuracy: 0.0000e+00 - val_loss: 2.2241e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 183/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0029 - accuracy: 0.0000e+00 - val_loss: 2.1041e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 184/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0032 - accuracy: 0.0000e+00 - val_loss: 2.1364e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 185/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0031 - accuracy: 0.0000e+00 - val_loss: 2.2422e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 186/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0034 - accuracy: 0.0000e+00 - val_loss: 2.4882e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 187/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0027 - accuracy: 0.0000e+00 - val_loss: 3.3094e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 188/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0027 - accuracy: 0.0000e+00 - val_loss: 2.3017e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 189/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0026 - accuracy: 0.0000e+00 - val_loss: 2.1538e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 190/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0026 - accuracy: 0.0000e+00 - val_loss: 2.0166e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 191/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0026 - accuracy: 0.0000e+00 - val_loss: 1.9271e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 192/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0025 - accuracy: 0.0000e+00 - val_loss: 2.2907e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 193/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0029 - accuracy: 0.0000e+00 - val_loss: 2.0644e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 194/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0021 - accuracy: 0.0000e+00 - val_loss: 2.8517e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 195/200\n",
            "18/18 [==============================] - 1s 52ms/step - loss: 0.0031 - accuracy: 0.0000e+00 - val_loss: 2.4214e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 196/200\n",
            "18/18 [==============================] - 1s 55ms/step - loss: 0.0031 - accuracy: 0.0000e+00 - val_loss: 2.0169e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 197/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0021 - accuracy: 0.0000e+00 - val_loss: 2.0956e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 198/200\n",
            "18/18 [==============================] - 1s 52ms/step - loss: 0.0028 - accuracy: 0.0000e+00 - val_loss: 2.1277e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 199/200\n",
            "18/18 [==============================] - 1s 53ms/step - loss: 0.0032 - accuracy: 0.0000e+00 - val_loss: 2.2824e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 200/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0031 - accuracy: 0.0000e+00 - val_loss: 2.7183e-04 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(572,) (144,)\n",
            "Train data RMSE:  0.025554046516645133\n",
            "Train data MSE:  0.0006530092933748632\n",
            "Train data MAE:  0.020021200314556623\n",
            "-------------------------------------------------------------------------------------\n",
            "Test data RMSE:  0.016487316004260916\n",
            "Test data MSE:  0.0002718315890243582\n",
            "Test data MAE:  0.013386402247463854\n",
            "Train data R2 score: -1.788203930973594\n",
            "Test data R2 score: -0.6338287309619899\n",
            "Train data MGD:  0.0006557352069706957\n",
            "Test data MGD:  0.00027508889332863686\n",
            "----------------------------------------------------------------------\n",
            "Train data MPD:  0.0006542314286006341\n",
            "Test data MPD:  0.0002734402226410458\n",
            "(716, 15, 191) (716,)\n",
            "Epoch 1/200\n",
            "18/18 [==============================] - 4s 64ms/step - loss: 0.8504 - accuracy: 0.0000e+00 - val_loss: 0.2050 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/200\n",
            "18/18 [==============================] - 1s 45ms/step - loss: 0.2838 - accuracy: 0.0000e+00 - val_loss: 0.0393 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/200\n",
            "18/18 [==============================] - 1s 45ms/step - loss: 0.1687 - accuracy: 0.0000e+00 - val_loss: 0.0577 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/200\n",
            "18/18 [==============================] - 1s 45ms/step - loss: 0.1404 - accuracy: 0.0000e+00 - val_loss: 0.0506 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.1282 - accuracy: 0.0000e+00 - val_loss: 0.0435 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.1340 - accuracy: 0.0000e+00 - val_loss: 0.0394 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/200\n",
            "18/18 [==============================] - 1s 45ms/step - loss: 0.1292 - accuracy: 0.0000e+00 - val_loss: 0.0389 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.1027 - accuracy: 0.0000e+00 - val_loss: 0.0345 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/200\n",
            "18/18 [==============================] - 1s 45ms/step - loss: 0.0873 - accuracy: 0.0000e+00 - val_loss: 0.0322 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/200\n",
            "18/18 [==============================] - 1s 45ms/step - loss: 0.0874 - accuracy: 0.0000e+00 - val_loss: 0.0316 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/200\n",
            "18/18 [==============================] - 1s 45ms/step - loss: 0.0934 - accuracy: 0.0000e+00 - val_loss: 0.0300 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/200\n",
            "18/18 [==============================] - 1s 45ms/step - loss: 0.0757 - accuracy: 0.0000e+00 - val_loss: 0.0282 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/200\n",
            "18/18 [==============================] - 1s 45ms/step - loss: 0.0833 - accuracy: 0.0000e+00 - val_loss: 0.0270 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0726 - accuracy: 0.0000e+00 - val_loss: 0.0258 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/200\n",
            "18/18 [==============================] - 1s 45ms/step - loss: 0.0725 - accuracy: 0.0000e+00 - val_loss: 0.0240 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0668 - accuracy: 0.0000e+00 - val_loss: 0.0222 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0579 - accuracy: 0.0000e+00 - val_loss: 0.0207 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0614 - accuracy: 0.0000e+00 - val_loss: 0.0199 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0600 - accuracy: 0.0000e+00 - val_loss: 0.0187 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/200\n",
            "18/18 [==============================] - 1s 45ms/step - loss: 0.0495 - accuracy: 0.0000e+00 - val_loss: 0.0177 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0541 - accuracy: 0.0000e+00 - val_loss: 0.0162 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0545 - accuracy: 0.0000e+00 - val_loss: 0.0152 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0455 - accuracy: 0.0000e+00 - val_loss: 0.0144 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0506 - accuracy: 0.0000e+00 - val_loss: 0.0137 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0457 - accuracy: 0.0000e+00 - val_loss: 0.0131 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0426 - accuracy: 0.0000e+00 - val_loss: 0.0132 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0356 - accuracy: 0.0000e+00 - val_loss: 0.0117 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0363 - accuracy: 0.0000e+00 - val_loss: 0.0116 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0366 - accuracy: 0.0000e+00 - val_loss: 0.0110 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0370 - accuracy: 0.0000e+00 - val_loss: 0.0120 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0370 - accuracy: 0.0000e+00 - val_loss: 0.0101 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0330 - accuracy: 0.0000e+00 - val_loss: 0.0097 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/200\n",
            "18/18 [==============================] - 1s 45ms/step - loss: 0.0299 - accuracy: 0.0000e+00 - val_loss: 0.0087 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0302 - accuracy: 0.0000e+00 - val_loss: 0.0084 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0311 - accuracy: 0.0000e+00 - val_loss: 0.0079 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0275 - accuracy: 0.0000e+00 - val_loss: 0.0079 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0270 - accuracy: 0.0000e+00 - val_loss: 0.0075 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0241 - accuracy: 0.0000e+00 - val_loss: 0.0069 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0267 - accuracy: 0.0000e+00 - val_loss: 0.0072 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0217 - accuracy: 0.0000e+00 - val_loss: 0.0062 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0237 - accuracy: 0.0000e+00 - val_loss: 0.0060 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0210 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0243 - accuracy: 0.0000e+00 - val_loss: 0.0056 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0199 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0229 - accuracy: 0.0000e+00 - val_loss: 0.0056 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0196 - accuracy: 0.0000e+00 - val_loss: 0.0050 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0164 - accuracy: 0.0000e+00 - val_loss: 0.0048 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0183 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0170 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0196 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0150 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0156 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0159 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0142 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0152 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0183 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0160 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0119 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0150 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0118 - accuracy: 0.0000e+00 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0120 - accuracy: 0.0000e+00 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0123 - accuracy: 0.0000e+00 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0122 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0138 - accuracy: 0.0000e+00 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0098 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0119 - accuracy: 0.0000e+00 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0101 - accuracy: 0.0000e+00 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0115 - accuracy: 0.0000e+00 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0101 - accuracy: 0.0000e+00 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0111 - accuracy: 0.0000e+00 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0088 - accuracy: 0.0000e+00 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0100 - accuracy: 0.0000e+00 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/200\n",
            "18/18 [==============================] - 1s 45ms/step - loss: 0.0072 - accuracy: 0.0000e+00 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0104 - accuracy: 0.0000e+00 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0078 - accuracy: 0.0000e+00 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0088 - accuracy: 0.0000e+00 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/200\n",
            "18/18 [==============================] - 1s 45ms/step - loss: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 81/200\n",
            "18/18 [==============================] - 1s 45ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0063 - accuracy: 0.0000e+00 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0078 - accuracy: 0.0000e+00 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0068 - accuracy: 0.0000e+00 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 86/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0073 - accuracy: 0.0000e+00 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0072 - accuracy: 0.0000e+00 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0073 - accuracy: 0.0000e+00 - val_loss: 9.9189e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0085 - accuracy: 0.0000e+00 - val_loss: 9.4800e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0064 - accuracy: 0.0000e+00 - val_loss: 9.5688e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0059 - accuracy: 0.0000e+00 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 92/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0076 - accuracy: 0.0000e+00 - val_loss: 9.7334e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0063 - accuracy: 0.0000e+00 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0067 - accuracy: 0.0000e+00 - val_loss: 9.3761e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0059 - accuracy: 0.0000e+00 - val_loss: 8.7863e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0062 - accuracy: 0.0000e+00 - val_loss: 9.0008e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 97/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0067 - accuracy: 0.0000e+00 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 98/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0068 - accuracy: 0.0000e+00 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0065 - accuracy: 0.0000e+00 - val_loss: 9.3576e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 100/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0053 - accuracy: 0.0000e+00 - val_loss: 8.4065e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 101/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 8.8620e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 102/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0066 - accuracy: 0.0000e+00 - val_loss: 7.7764e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 103/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0051 - accuracy: 0.0000e+00 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 104/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0052 - accuracy: 0.0000e+00 - val_loss: 8.6330e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 105/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0050 - accuracy: 0.0000e+00 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 106/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0056 - accuracy: 0.0000e+00 - val_loss: 8.1473e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 107/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 108/200\n",
            "18/18 [==============================] - 1s 83ms/step - loss: 0.0052 - accuracy: 0.0000e+00 - val_loss: 9.9104e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 109/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0060 - accuracy: 0.0000e+00 - val_loss: 7.6913e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 110/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0056 - accuracy: 0.0000e+00 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 111/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 8.3826e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 112/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0051 - accuracy: 0.0000e+00 - val_loss: 6.9377e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 113/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 6.3179e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 114/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0051 - accuracy: 0.0000e+00 - val_loss: 7.9714e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 115/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0066 - accuracy: 0.0000e+00 - val_loss: 6.7113e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 116/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 7.4591e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 117/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0049 - accuracy: 0.0000e+00 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 118/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0055 - accuracy: 0.0000e+00 - val_loss: 9.3473e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 119/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 120/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0049 - accuracy: 0.0000e+00 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 121/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0052 - accuracy: 0.0000e+00 - val_loss: 8.2728e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 122/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 123/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 124/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 125/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0050 - accuracy: 0.0000e+00 - val_loss: 6.1568e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 126/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0049 - accuracy: 0.0000e+00 - val_loss: 5.7414e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 127/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 7.5576e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 128/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 5.9950e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 129/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 5.8354e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 130/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 6.8034e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 131/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 5.2887e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 132/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 8.6865e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 133/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 7.6221e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 134/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 6.2502e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 135/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 6.4784e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 136/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0031 - accuracy: 0.0000e+00 - val_loss: 9.2914e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 137/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0031 - accuracy: 0.0000e+00 - val_loss: 6.5771e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 138/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0032 - accuracy: 0.0000e+00 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 139/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 7.0795e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 140/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 5.8358e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 141/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 9.4337e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 142/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0031 - accuracy: 0.0000e+00 - val_loss: 6.1729e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 143/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0031 - accuracy: 0.0000e+00 - val_loss: 7.1202e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 144/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 7.9253e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 145/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 5.7857e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 146/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0033 - accuracy: 0.0000e+00 - val_loss: 7.9742e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 147/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0030 - accuracy: 0.0000e+00 - val_loss: 8.0756e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 148/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 7.4533e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 149/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0030 - accuracy: 0.0000e+00 - val_loss: 9.2311e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 150/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 5.6977e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 151/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 6.3019e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 152/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 4.8773e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 153/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 4.6976e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 154/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0032 - accuracy: 0.0000e+00 - val_loss: 6.3372e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 155/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0031 - accuracy: 0.0000e+00 - val_loss: 6.4353e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 156/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 7.1452e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 157/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 5.4673e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 158/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0024 - accuracy: 0.0000e+00 - val_loss: 5.0371e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 159/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 6.2114e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 160/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0031 - accuracy: 0.0000e+00 - val_loss: 8.1909e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 161/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0026 - accuracy: 0.0000e+00 - val_loss: 7.3310e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 162/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0032 - accuracy: 0.0000e+00 - val_loss: 5.1049e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 163/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0030 - accuracy: 0.0000e+00 - val_loss: 5.9869e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 164/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0031 - accuracy: 0.0000e+00 - val_loss: 6.3657e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 165/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0029 - accuracy: 0.0000e+00 - val_loss: 5.2867e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 166/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0031 - accuracy: 0.0000e+00 - val_loss: 5.6699e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 167/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0029 - accuracy: 0.0000e+00 - val_loss: 4.8317e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 168/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0033 - accuracy: 0.0000e+00 - val_loss: 7.3301e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 169/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0028 - accuracy: 0.0000e+00 - val_loss: 4.6539e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 170/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0029 - accuracy: 0.0000e+00 - val_loss: 5.5164e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 171/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0025 - accuracy: 0.0000e+00 - val_loss: 8.7736e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 172/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 8.4112e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 173/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0028 - accuracy: 0.0000e+00 - val_loss: 9.2565e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 174/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0025 - accuracy: 0.0000e+00 - val_loss: 6.3422e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 175/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0025 - accuracy: 0.0000e+00 - val_loss: 7.7846e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 176/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0027 - accuracy: 0.0000e+00 - val_loss: 5.3503e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 177/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0027 - accuracy: 0.0000e+00 - val_loss: 4.7496e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 178/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0027 - accuracy: 0.0000e+00 - val_loss: 4.6007e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 179/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0021 - accuracy: 0.0000e+00 - val_loss: 5.4484e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 180/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0028 - accuracy: 0.0000e+00 - val_loss: 6.1151e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 181/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0022 - accuracy: 0.0000e+00 - val_loss: 6.1395e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 182/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0025 - accuracy: 0.0000e+00 - val_loss: 4.4309e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 183/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0022 - accuracy: 0.0000e+00 - val_loss: 5.4759e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 184/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0022 - accuracy: 0.0000e+00 - val_loss: 4.8132e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 185/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0024 - accuracy: 0.0000e+00 - val_loss: 4.3434e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 186/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0024 - accuracy: 0.0000e+00 - val_loss: 4.6577e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 187/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0024 - accuracy: 0.0000e+00 - val_loss: 4.2238e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 188/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0026 - accuracy: 0.0000e+00 - val_loss: 4.1372e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 189/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0025 - accuracy: 0.0000e+00 - val_loss: 6.2537e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 190/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0025 - accuracy: 0.0000e+00 - val_loss: 4.1028e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 191/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 3.8923e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 192/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0021 - accuracy: 0.0000e+00 - val_loss: 6.9666e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 193/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0025 - accuracy: 0.0000e+00 - val_loss: 5.7948e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 194/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0021 - accuracy: 0.0000e+00 - val_loss: 3.8148e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 195/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 3.4098e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 196/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 3.4855e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 197/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 3.9745e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 198/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0025 - accuracy: 0.0000e+00 - val_loss: 3.6874e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 199/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0026 - accuracy: 0.0000e+00 - val_loss: 4.2690e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 200/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0021 - accuracy: 0.0000e+00 - val_loss: 3.7415e-04 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(572,) (144,)\n",
            "Train data RMSE:  0.021229470885032155\n",
            "Train data MSE:  0.000450690434058428\n",
            "Train data MAE:  0.016299864508189866\n",
            "-------------------------------------------------------------------------------------\n",
            "Test data RMSE:  0.019342924528277988\n",
            "Test data MSE:  0.00037414872930665823\n",
            "Test data MAE:  0.01544010350828569\n",
            "Train data R2 score: -0.14516141022765838\n",
            "Test data R2 score: -0.7099430659593147\n",
            "Train data MGD:  0.0004489534841900472\n",
            "Test data MGD:  0.0003783256711202338\n",
            "----------------------------------------------------------------------\n",
            "Train data MPD:  0.0004497142695827167\n",
            "Test data MPD:  0.00037620654957420024\n",
            "(716, 15, 191) (716,)\n",
            "Epoch 1/200\n",
            "18/18 [==============================] - 3s 68ms/step - loss: 0.5464 - accuracy: 0.0000e+00 - val_loss: 0.0424 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.2897 - accuracy: 0.0000e+00 - val_loss: 0.1493 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.2292 - accuracy: 0.0000e+00 - val_loss: 0.1186 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.2153 - accuracy: 0.0000e+00 - val_loss: 0.0668 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.1758 - accuracy: 0.0000e+00 - val_loss: 0.0498 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.1611 - accuracy: 0.0000e+00 - val_loss: 0.0481 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.1382 - accuracy: 0.0000e+00 - val_loss: 0.0491 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.1327 - accuracy: 0.0000e+00 - val_loss: 0.0313 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.1246 - accuracy: 0.0000e+00 - val_loss: 0.0326 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/200\n",
            "18/18 [==============================] - 1s 45ms/step - loss: 0.1128 - accuracy: 0.0000e+00 - val_loss: 0.0366 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0990 - accuracy: 0.0000e+00 - val_loss: 0.0342 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.1057 - accuracy: 0.0000e+00 - val_loss: 0.0270 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0846 - accuracy: 0.0000e+00 - val_loss: 0.0368 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0793 - accuracy: 0.0000e+00 - val_loss: 0.0292 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0747 - accuracy: 0.0000e+00 - val_loss: 0.0242 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0710 - accuracy: 0.0000e+00 - val_loss: 0.0247 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0625 - accuracy: 0.0000e+00 - val_loss: 0.0204 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0694 - accuracy: 0.0000e+00 - val_loss: 0.0200 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0550 - accuracy: 0.0000e+00 - val_loss: 0.0168 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0505 - accuracy: 0.0000e+00 - val_loss: 0.0168 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0506 - accuracy: 0.0000e+00 - val_loss: 0.0173 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/200\n",
            "18/18 [==============================] - 1s 45ms/step - loss: 0.0514 - accuracy: 0.0000e+00 - val_loss: 0.0177 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0381 - accuracy: 0.0000e+00 - val_loss: 0.0098 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0422 - accuracy: 0.0000e+00 - val_loss: 0.0168 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0405 - accuracy: 0.0017 - val_loss: 0.0140 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0338 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0405 - accuracy: 0.0000e+00 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0355 - accuracy: 0.0000e+00 - val_loss: 0.0078 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0323 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0293 - accuracy: 0.0000e+00 - val_loss: 0.0075 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0294 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0281 - accuracy: 0.0000e+00 - val_loss: 0.0073 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0258 - accuracy: 0.0000e+00 - val_loss: 0.0060 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0251 - accuracy: 0.0000e+00 - val_loss: 0.0088 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0228 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0269 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0237 - accuracy: 0.0000e+00 - val_loss: 0.0049 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0223 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0239 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0218 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0186 - accuracy: 0.0000e+00 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0211 - accuracy: 0.0000e+00 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0177 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0158 - accuracy: 0.0000e+00 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0184 - accuracy: 0.0000e+00 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0164 - accuracy: 0.0000e+00 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0160 - accuracy: 0.0000e+00 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0151 - accuracy: 0.0000e+00 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0155 - accuracy: 0.0000e+00 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0151 - accuracy: 0.0000e+00 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0156 - accuracy: 0.0000e+00 - val_loss: 7.7289e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0148 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0139 - accuracy: 0.0000e+00 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0141 - accuracy: 0.0000e+00 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0139 - accuracy: 0.0000e+00 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0142 - accuracy: 0.0000e+00 - val_loss: 8.2401e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0120 - accuracy: 0.0000e+00 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/200\n",
            "18/18 [==============================] - 1s 52ms/step - loss: 0.0133 - accuracy: 0.0000e+00 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0117 - accuracy: 0.0000e+00 - val_loss: 7.0969e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0114 - accuracy: 0.0000e+00 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0133 - accuracy: 0.0000e+00 - val_loss: 8.3220e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0117 - accuracy: 0.0000e+00 - val_loss: 9.4030e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0110 - accuracy: 0.0000e+00 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0108 - accuracy: 0.0000e+00 - val_loss: 6.7833e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0113 - accuracy: 0.0000e+00 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0112 - accuracy: 0.0000e+00 - val_loss: 9.7716e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0098 - accuracy: 0.0000e+00 - val_loss: 9.0410e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0101 - accuracy: 0.0000e+00 - val_loss: 7.8113e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0112 - accuracy: 0.0000e+00 - val_loss: 9.8373e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0092 - accuracy: 0.0000e+00 - val_loss: 7.3768e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0095 - accuracy: 0.0000e+00 - val_loss: 9.4019e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0094 - accuracy: 0.0000e+00 - val_loss: 5.7883e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 8.9403e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0092 - accuracy: 0.0000e+00 - val_loss: 6.3170e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0098 - accuracy: 0.0000e+00 - val_loss: 7.7555e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0087 - accuracy: 0.0000e+00 - val_loss: 7.3058e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0096 - accuracy: 0.0000e+00 - val_loss: 6.3583e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0092 - accuracy: 0.0000e+00 - val_loss: 8.6425e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0099 - accuracy: 0.0000e+00 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 5.1947e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 81/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0080 - accuracy: 0.0000e+00 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0093 - accuracy: 0.0000e+00 - val_loss: 4.1755e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0087 - accuracy: 0.0000e+00 - val_loss: 7.0788e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 86/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0088 - accuracy: 0.0000e+00 - val_loss: 6.7847e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0089 - accuracy: 0.0000e+00 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0094 - accuracy: 0.0000e+00 - val_loss: 8.0253e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0075 - accuracy: 0.0000e+00 - val_loss: 9.0724e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0075 - accuracy: 0.0000e+00 - val_loss: 8.1636e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 92/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0074 - accuracy: 0.0000e+00 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0075 - accuracy: 0.0000e+00 - val_loss: 6.6618e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0075 - accuracy: 0.0000e+00 - val_loss: 8.5070e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 4.7263e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 97/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0079 - accuracy: 0.0000e+00 - val_loss: 7.9133e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 98/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0077 - accuracy: 0.0000e+00 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0076 - accuracy: 0.0000e+00 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 100/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0070 - accuracy: 0.0000e+00 - val_loss: 9.4502e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 101/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0071 - accuracy: 0.0000e+00 - val_loss: 6.8349e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 102/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0073 - accuracy: 0.0000e+00 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 103/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0070 - accuracy: 0.0000e+00 - val_loss: 5.0318e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 104/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0067 - accuracy: 0.0000e+00 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 105/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0068 - accuracy: 0.0000e+00 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 106/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0075 - accuracy: 0.0000e+00 - val_loss: 6.6005e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 107/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0070 - accuracy: 0.0000e+00 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 108/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0076 - accuracy: 0.0000e+00 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 109/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0077 - accuracy: 0.0000e+00 - val_loss: 5.2516e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 110/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0073 - accuracy: 0.0000e+00 - val_loss: 6.0604e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 111/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0077 - accuracy: 0.0000e+00 - val_loss: 4.9484e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 112/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0065 - accuracy: 0.0000e+00 - val_loss: 4.3286e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 113/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0076 - accuracy: 0.0000e+00 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 114/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0066 - accuracy: 0.0000e+00 - val_loss: 8.5548e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 115/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0065 - accuracy: 0.0000e+00 - val_loss: 3.1177e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 116/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0077 - accuracy: 0.0000e+00 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 117/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0072 - accuracy: 0.0000e+00 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 118/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0062 - accuracy: 0.0000e+00 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 119/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0073 - accuracy: 0.0000e+00 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 120/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0076 - accuracy: 0.0000e+00 - val_loss: 3.4570e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 121/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0059 - accuracy: 0.0000e+00 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 122/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0069 - accuracy: 0.0000e+00 - val_loss: 8.5422e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 123/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0063 - accuracy: 0.0000e+00 - val_loss: 8.5119e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 124/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0062 - accuracy: 0.0000e+00 - val_loss: 9.2311e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 125/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0059 - accuracy: 0.0000e+00 - val_loss: 7.1193e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 126/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0065 - accuracy: 0.0000e+00 - val_loss: 9.2268e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 127/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0066 - accuracy: 0.0000e+00 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 128/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0060 - accuracy: 0.0000e+00 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 129/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0062 - accuracy: 0.0000e+00 - val_loss: 6.7974e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 130/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0076 - accuracy: 0.0000e+00 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 131/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0059 - accuracy: 0.0000e+00 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 132/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0055 - accuracy: 0.0000e+00 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 133/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0058 - accuracy: 0.0000e+00 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 134/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0061 - accuracy: 0.0000e+00 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 135/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0066 - accuracy: 0.0000e+00 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 136/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0067 - accuracy: 0.0000e+00 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 137/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0068 - accuracy: 0.0000e+00 - val_loss: 7.9215e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 138/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0074 - accuracy: 0.0000e+00 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 139/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0072 - accuracy: 0.0000e+00 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 140/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0061 - accuracy: 0.0000e+00 - val_loss: 9.9299e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 141/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0060 - accuracy: 0.0000e+00 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 142/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0063 - accuracy: 0.0000e+00 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 143/200\n",
            "18/18 [==============================] - 1s 52ms/step - loss: 0.0065 - accuracy: 0.0000e+00 - val_loss: 8.4810e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 144/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0066 - accuracy: 0.0000e+00 - val_loss: 8.9677e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 145/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0056 - accuracy: 0.0000e+00 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 146/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0059 - accuracy: 0.0000e+00 - val_loss: 5.4459e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 147/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0058 - accuracy: 0.0000e+00 - val_loss: 6.0002e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 148/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0059 - accuracy: 0.0000e+00 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 149/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0059 - accuracy: 0.0000e+00 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 150/200\n",
            "18/18 [==============================] - 1s 53ms/step - loss: 0.0066 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 151/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0064 - accuracy: 0.0000e+00 - val_loss: 7.3237e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 152/200\n",
            "18/18 [==============================] - 1s 52ms/step - loss: 0.0062 - accuracy: 0.0000e+00 - val_loss: 6.8848e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 153/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0065 - accuracy: 0.0000e+00 - val_loss: 6.3495e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 154/200\n",
            "18/18 [==============================] - 1s 53ms/step - loss: 0.0053 - accuracy: 0.0000e+00 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 155/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0066 - accuracy: 0.0000e+00 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 156/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0055 - accuracy: 0.0000e+00 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 157/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0058 - accuracy: 0.0000e+00 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 158/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0058 - accuracy: 0.0000e+00 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 159/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0063 - accuracy: 0.0000e+00 - val_loss: 4.8196e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 160/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0062 - accuracy: 0.0000e+00 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 161/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0067 - accuracy: 0.0000e+00 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 162/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0058 - accuracy: 0.0000e+00 - val_loss: 5.4533e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 163/200\n",
            "18/18 [==============================] - 1s 53ms/step - loss: 0.0054 - accuracy: 0.0000e+00 - val_loss: 9.9163e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 164/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0059 - accuracy: 0.0000e+00 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 165/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0059 - accuracy: 0.0000e+00 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 166/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0062 - accuracy: 0.0000e+00 - val_loss: 9.4166e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 167/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0061 - accuracy: 0.0000e+00 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 168/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0060 - accuracy: 0.0000e+00 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
            "Epoch 169/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0059 - accuracy: 0.0000e+00 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 170/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0056 - accuracy: 0.0000e+00 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 171/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0062 - accuracy: 0.0000e+00 - val_loss: 7.2832e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 172/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0060 - accuracy: 0.0000e+00 - val_loss: 0.0022 - val_accuracy: 0.0000e+00\n",
            "Epoch 173/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0061 - accuracy: 0.0000e+00 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 174/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0066 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
            "Epoch 175/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0062 - accuracy: 0.0000e+00 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 176/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0062 - accuracy: 0.0000e+00 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 177/200\n",
            "18/18 [==============================] - 1s 52ms/step - loss: 0.0056 - accuracy: 0.0000e+00 - val_loss: 7.8460e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 178/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0060 - accuracy: 0.0000e+00 - val_loss: 5.3776e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 179/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0057 - accuracy: 0.0000e+00 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 180/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0065 - accuracy: 0.0000e+00 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 181/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0060 - accuracy: 0.0000e+00 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 182/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0060 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 183/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0061 - accuracy: 0.0000e+00 - val_loss: 9.6387e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 184/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0058 - accuracy: 0.0000e+00 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 185/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0065 - accuracy: 0.0000e+00 - val_loss: 9.4776e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 186/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0055 - accuracy: 0.0000e+00 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 187/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0057 - accuracy: 0.0000e+00 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 188/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0059 - accuracy: 0.0000e+00 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 189/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0054 - accuracy: 0.0000e+00 - val_loss: 6.9664e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 190/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0061 - accuracy: 0.0000e+00 - val_loss: 7.8630e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 191/200\n",
            "18/18 [==============================] - 1s 53ms/step - loss: 0.0054 - accuracy: 0.0000e+00 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 192/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0055 - accuracy: 0.0000e+00 - val_loss: 9.1712e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 193/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0059 - accuracy: 0.0000e+00 - val_loss: 7.4861e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 194/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0060 - accuracy: 0.0000e+00 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 195/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0055 - accuracy: 0.0000e+00 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 196/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0055 - accuracy: 0.0000e+00 - val_loss: 7.6411e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 197/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0057 - accuracy: 0.0000e+00 - val_loss: 6.1936e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 198/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0055 - accuracy: 0.0000e+00 - val_loss: 7.6185e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 199/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0057 - accuracy: 0.0000e+00 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 200/200\n",
            "18/18 [==============================] - 1s 52ms/step - loss: 0.0061 - accuracy: 0.0000e+00 - val_loss: 6.5510e-04 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU9b3/8deHJBDIwpKwCEESLIsoewBXRGurqAUXrHKtyvW6ttbtWku1KtfW3+298uv18rvaVmvVWlq0tVqqeLGKijuLIhIEBQQNAkLYAiGEJN/fH98zyZCdZDKTmbyfj8c8ZubMWT7znTOf8z3fc873mHMOERGJfx1iHYCIiESGErqISIJQQhcRSRBK6CIiCUIJXUQkQSihi4gkCCV0qZOZvWRmV0Z63Fgys41mdmYrzNeZ2TeC1782s7ubMm4zlnOZmb3c3DgbmO8kMyuM9Hwl+pJjHYBEjpntC3vbBTgIVATvr3POzW3qvJxzk1tj3ETnnLs+EvMxs1zgcyDFOVcezHsu0OTfUNofJfQE4pxLD702s43A1c65V2qOZ2bJoSQhIolDTS7tQGiX2sx+bGZbgcfNrLuZvWBm281sV/A6J2ya183s6uD1DDN7y8xmB+N+bmaTmzlunpktNrNiM3vFzB4ysz/UE3dTYvyZmb0dzO9lM8sO+/xyM9tkZkVmdlcD5TPBzLaaWVLYsAvMbGXweryZvWtmu81si5n9j5l1rGdeT5jZz8Pe/yiY5iszu6rGuOea2YdmttfMvjSzWWEfLw6ed5vZPjM7MVS2YdOfZGZLzWxP8HxSU8umIWZ2bDD9bjMrMLMpYZ+dY2arg3luNrPbg+HZwe+z28x2mtmbZqb8EmUq8PajD9ADGABci//tHw/eHw0cAP6ngeknAGuBbOA/gcfMzJox7h+BJUAWMAu4vIFlNiXGfwL+GegFdARCCWYY8Ktg/n2D5eVQB+fc+8B+4Iwa8/1j8LoCuDX4PicC3wS+30DcBDGcHcTzLWAQULP9fj9wBdANOBe4wczODz6bGDx3c86lO+ferTHvHsCLwJzgu/0SeNHMsmp8h1pl00jMKcDfgZeD6X4IzDWzIcEoj+Gb7zKA44FFwfB/BQqBnkBv4E5A/YpEmRJ6+1EJ3OucO+icO+CcK3LOPeucK3HOFQP3A6c1MP0m59yjzrkK4EngKPwft8njmtnRwDjgHudcmXPuLWB+fQtsYoyPO+c+dc4dAJ4BRgXDpwEvOOcWO+cOAncHZVCfPwHTAcwsAzgnGIZzbrlz7j3nXLlzbiPwmzriqMt3g/hWOef24zdg4d/vdefcx865SufcymB5TZkv+A3AZ865p4K4/gSsAb4TNk59ZdOQE4B04BfBb7QIeIGgbIBDwDAzy3TO7XLOfRA2/ChggHPukHPuTaeOoqJOCb392O6cKw29MbMuZvaboEliL34Xv1t4s0MNW0MvnHMlwcv0Ixy3L7AzbBjAl/UF3MQYt4a9LgmLqW/4vIOEWlTfsvC18QvNrBNwIfCBc25TEMfgoDlhaxDH/8HX1htzWAzAphrfb4KZvRY0Ke0Brm/ifEPz3lRj2CagX9j7+sqm0Zidc+Ebv/D5XoTf2G0yszfM7MRg+APAOuBlM9tgZjOb9jUkkpTQ24+ataV/BYYAE5xzmVTv4tfXjBIJW4AeZtYlbFj/BsZvSYxbwucdLDOrvpGdc6vxiWsyhze3gG+6WQMMCuK4szkx4JuNwv0Rv4fS3znXFfh12Hwbq91+hW+KCnc0sLkJcTU23/412r+r5uucW+qcm4pvjnkeX/PHOVfsnPtX59xAYApwm5l9s4WxyBFSQm+/MvBt0ruD9th7W3uBQY13GTDLzDoGtbvvNDBJS2L8C3CemZ0SHMC8j8bX9z8CN+M3HH+uEcdeYJ+ZDQVuaGIMzwAzzGxYsEGpGX8Gfo+l1MzG4zckIdvxTUQD65n3AmCwmf2TmSWb2SXAMHzzSEu8j6/N32FmKWY2Cf8bzQt+s8vMrKtz7hC+TCoBzOw8M/tGcKxkD/64Q0NNXNIKlNDbrweBzsAO4D3gf6O03MvwBxaLgJ8DT+PPl69Ls2N0zhUAP8An6S3ALvxBu4aE2rAXOed2hA2/HZ9si4FHg5ibEsNLwXdYhG+OWFRjlO8D95lZMXAPQW03mLYEf8zg7eDMkRNqzLsIOA+/F1ME3AGcVyPuI+acK8Mn8Mn4cn8YuMI5tyYY5XJgY9D0dD3+9wR/0PcVYB/wLvCwc+61lsQiR8503EJiycyeBtY451p9D0Ek0amGLlFlZuPM7Bgz6xCc1jcV3xYrIi2kK0Ul2voAf8UfoCwEbnDOfRjbkEQSg5pcREQShJpcREQSRMyaXLKzs11ubm6sFi8iEpeWL1++wznXs67PYpbQc3NzWbZsWawWLyISl8ys5hXCVdTkIiKSIJTQRUQShBK6iEiC0HnoIu3IoUOHKCwspLS0tPGRJaZSU1PJyckhJSWlydMooYu0I4WFhWRkZJCbm0v99yeRWHPOUVRURGFhIXl5eU2eTk0uIu1IaWkpWVlZSuZtnJmRlZV1xHtSSugi7YySeXxozu8Ufwn9rbfg7rvh0KFYRyIi0qbEX0J/7z34+c/hYH1daItIW1VUVMSoUaMYNWoUffr0oV+/flXvy8rKGpx22bJl3HTTTY0u46STTopIrK+//jrnnXdeROYVLfF3UDQ5CLm8PLZxiMgRy8rKYsWKFQDMmjWL9PR0br/99qrPy8vLSU6uOy3l5+eTn5/f6DLeeeedyAQbh+Kvhq6ELpJQZsyYwfXXX8+ECRO44447WLJkCSeeeCKjR4/mpJNOYu3atcDhNeZZs2Zx1VVXMWnSJAYOHMicOXOq5peenl41/qRJk5g2bRpDhw7lsssuI9S77IIFCxg6dChjx47lpptuarQmvnPnTs4//3xGjBjBCSecwMqVKwF44403qvYwRo8eTXFxMVu2bGHixImMGjWK448/njfffDPiZVaf+K2hqw1dpGVuuQWC2nLEjBoFDz54xJMVFhbyzjvvkJSUxN69e3nzzTdJTk7mlVde4c477+TZZ5+tNc2aNWt47bXXKC4uZsiQIdxwww21ztn+8MMPKSgooG/fvpx88sm8/fbb5Ofnc91117F48WLy8vKYPn16o/Hde++9jB49mueff55FixZxxRVXsGLFCmbPns1DDz3EySefzL59+0hNTeWRRx7hrLPO4q677qKiooKSkpIjLo/mit+Erhq6SMK4+OKLSUpKAmDPnj1ceeWVfPbZZ5gZh+qpvJ177rl06tSJTp060atXL7Zt20ZOTs5h44wfP75q2KhRo9i4cSPp6ekMHDiw6vzu6dOn88gjjzQY31tvvVW1UTnjjDMoKipi7969nHzyydx2221cdtllXHjhheTk5DBu3DiuuuoqDh06xPnnn8+oUaNaVDZHIv4SemgLrIQu0jLNqEm3lrS0tKrXd999N6effjrPPfccGzduZNKkSXVO06lTp6rXSUlJlNeRE5oyTkvMnDmTc889lwULFnDyySezcOFCJk6cyOLFi3nxxReZMWMGt912G1dccUVEl1sftaGLSJuyZ88e+vXrB8ATTzwR8fkPGTKEDRs2sHHjRgCefvrpRqc59dRTmTt3LuDb5rOzs8nMzGT9+vUMHz6cH//4x4wbN441a9awadMmevfuzTXXXMPVV1/NBx98EPHvUB8ldBFpU+644w5+8pOfMHr06IjXqAE6d+7Mww8/zNlnn83YsWPJyMiga9euDU4za9Ysli9fzogRI5g5cyZPPvkkAA8++CDHH388I0aMICUlhcmTJ/P6668zcuRIRo8ezdNPP83NN98c8e9Qn5jdUzQ/P9816wYXzz4L06bBRx/BiBGRD0wkgX3yyScce+yxsQ4j5vbt20d6ejrOOX7wgx8waNAgbr311liHVUtdv5eZLXfO1Xn+ZvzV0NWGLiIt9OijjzJq1CiOO+449uzZw3XXXRfrkCIi/g6KqslFRFro1ltvbZM18paKvxq6ErqISJ2U0EVEEkT8JnRdKSoicpgmJXQzO9vM1prZOjObWcfnM8xsu5mtCB5XRz7UgA6KiojUqdGEbmZJwEPAZGAYMN3MhtUx6tPOuVHB47cRjrOamlxE4tbpp5/OwoULDxv24IMPcsMNN9Q7zaRJkwid4nzOOeewe/fuWuPMmjWL2bNnN7js559/ntWrV1e9v+eee3jllVeOJPw6taVudptSQx8PrHPObXDOlQHzgKmtG1YDlNBF4tb06dOZN2/eYcPmzZvXpA6ywPeS2K1bt2Ytu2ZCv++++zjzzDObNa+2qikJvR/wZdj7wmBYTReZ2Uoz+4uZ9a9rRmZ2rZktM7Nl27dvb0a4KKGLxLFp06bx4osvVt3MYuPGjXz11Veceuqp3HDDDeTn53Pcccdx77331jl9bm4uO3bsAOD+++9n8ODBnHLKKVVd7II/x3zcuHGMHDmSiy66iJKSEt555x3mz5/Pj370I0aNGsX69euZMWMGf/nLXwB49dVXGT16NMOHD+eqq67iYHADndzcXO69917GjBnD8OHDWbNmTYPfL9bd7EbqPPS/A39yzh00s+uAJ4Ezao7knHsEeAT8laLNWpIOiopERCx6z+3Rowfjx4/npZdeYurUqcybN4/vfve7mBn3338/PXr0oKKigm9+85usXLmSEfVcDb58+XLmzZvHihUrKC8vZ8yYMYwdOxaACy+8kGuuuQaAn/70pzz22GP88Ic/ZMqUKZx33nlMmzbtsHmVlpYyY8YMXn31VQYPHswVV1zBr371K2655RYAsrOz+eCDD3j44YeZPXs2v/1t/S3Kse5mtyk19M1AeI07JxhWxTlX5JwL3RPut8DYFkdWHx0UFYlr4c0u4c0tzzzzDGPGjGH06NEUFBQc1jxS05tvvskFF1xAly5dyMzMZMqUKVWfrVq1ilNPPZXhw4czd+5cCgoKGoxn7dq15OXlMXjwYACuvPJKFi9eXPX5hRdeCMDYsWOrOvSqz1tvvcXll18O1N3N7pw5c9i9ezfJycmMGzeOxx9/nFmzZvHxxx+TkZHR4Lyboik19KXAIDPLwyfyS4F/Ch/BzI5yzm0J3k4BPmlxZPVRk4tIRMSq99ypU6dy66238sEHH1BSUsLYsWP5/PPPmT17NkuXLqV79+7MmDGD0tLSZs1/xowZPP/884wcOZInnniC119/vUXxhrrgbUn3u9HqZrfRGrpzrhy4EViIT9TPOOcKzOw+MwttFm8yswIz+wi4CZjRoqgaooQuEtfS09M5/fTTueqqq6pq53v37iUtLY2uXbuybds2XnrppQbnMXHiRJ5//nkOHDhAcXExf//736s+Ky4u5qijjuLQoUNVXd4CZGRkUFxcXGteQ4YMYePGjaxbtw6Ap556itNOO61Z3y3W3ew2qQ3dObcAWFBj2D1hr38C/KTF0TSFErpI3Js+fToXXHBBVdNLqLvZoUOH0r9/f04++eQGpx8zZgyXXHIJI0eOpFevXowbN67qs5/97GdMmDCBnj17MmHChKokfumll3LNNdcwZ86cqoOhAKmpqTz++ONcfPHFlJeXM27cOK6//vpmfa/QvU5HjBhBly5dDutm97XXXqNDhw4cd9xxTJ48mXnz5vHAAw+QkpJCeno6v//975u1zHDx131uURFkZ8OcOfDDH0Y+MJEEpu5z40vid5+rGrqISJ2U0EVEEoQSukg7E6tmVjkyzfmdlNBF2pHU1FSKioqU1Ns45xxFRUWkpqYe0XTxd8eipCQw05WiIs2Qk5NDYWEhze56Q6ImNTWVnJycI5om/hI6+Fq6augiRywlJYW8vLxYhyGtJP6aXEAJXUSkDkroIiIJIn4TutrQRUQOE58JPSVFNXQRkRriM6GryUVEpBYldBGRBKGELiKSIOIzoaek6KCoiEgN8ZnQVUMXEalFCV1EJEEooYuIJAgldBGRBBGfCV0HRUVEaonPhK4auohILUroIiIJQgldRCRBxGdCV+dcIiK1xGdCV/e5IiK1xG9CVw1dROQwSugiIgmiSQndzM42s7Vmts7MZjYw3kVm5swsP3Ih1kEJXUSklkYTupklAQ8Bk4FhwHQzG1bHeBnAzcD7kQ6yFh0UFRGppSk19PHAOufcBudcGTAPmFrHeD8D/gMojWB8ddNBURGRWpqS0PsBX4a9LwyGVTGzMUB/59yLDc3IzK41s2Vmtmz79u1HHGwVNbmIiNTS4oOiZtYB+CXwr42N65x7xDmX75zL79mzZ/MXqoQuIlJLUxL6ZqB/2PucYFhIBnA88LqZbQROAOa36oFRJXQRkVqaktCXAoPMLM/MOgKXAvNDHzrn9jjnsp1zuc65XOA9YIpzblmrRAzqbVFEpA6NJnTnXDlwI7AQ+AR4xjlXYGb3mdmU1g6wTqqhi4jUktyUkZxzC4AFNYbdU8+4k1oeViOSk6GiApwDs1ZfnIhIPIjfK0XBJ3UREQHiNaGnpPhnNbuIiFSJz4QeqqHrwKiISJX4TuiqoYuIVFFCFxFJEEroIiIJIj4Tug6KiojUEp8JXQdFRURqie+Erhq6iEgVJXQRkQQRnwldbegiIrXEZ0JXDV1EpJb4Tug6KCoiUiW+E7pq6CIiVZTQRUQSRHwmdB0UFRGpJT4TumroIiK1xHdC10FREZEq8Z3QVUMXEamihC4ikiDiM6HroKiISC3xmdBVQxcRqSW+E7oOioqIVInvhK4auohIlfhM6GpDFxGpJT4TumroIiK1xHdCVxu6iEiVJiV0MzvbzNaa2Tozm1nH59eb2cdmtsLM3jKzYZEPNYxq6CIitTSa0M0sCXgImAwMA6bXkbD/6Jwb7pwbBfwn8MuIRxpOCV1EpJam1NDHA+uccxucc2XAPGBq+AjOub1hb9MAF7kQ66CELiJSS3ITxukHfBn2vhCYUHMkM/sBcBvQETijrhmZ2bXAtQBHH330kcZarUMH/1BCFxGpErGDos65h5xzxwA/Bn5azziPOOfynXP5PXv2bNkCk5N1UFREJExTEvpmoH/Y+5xgWH3mAee3JKgmSU5WDV1EJExTEvpSYJCZ5ZlZR+BSYH74CGY2KOztucBnkQuxHkroIiKHabQN3TlXbmY3AguBJOB3zrkCM7sPWOacmw/caGZnAoeAXcCVrRk0AJ07Q0lJqy9GRCReNOWgKM65BcCCGsPuCXt9c4TjalyPHrBrV9QXKyLSVsXnlaLgE/rOnbGOQkSkzVBCFxFJEPGb0Lt3V0IXEQkTvwldNXQRkcPEd0IvLtbFRSIigfhO6AC7d8c2DhGRNiL+E7qaXUREACV0EZGEoYQuIpIglNBFRBKEErqISIKI34TetSuYKaGLiATiN6F36ADduimhi4gE4jehg64WFREJE/8JXV3oiogAiZDQVUMXEQGU0EVEEoYSuohIgoj/hL5rF1RWxjoSEZGYi++E3r27T+Z79sQ6EhGRmIvvhD54sH9evjy2cYiItAHxndDPOAM6d4a//S3WkYiIxFx8J/TOneHb34b588G5WEcjIhJT8Z3QAaZMgS++gJUrYx2JiEhMxX9CP/dc30mXml1EpJ2L/4Teuzcceyx8+GGsIxERian4T+gAOTmweXOsoxARiakmJXQzO9vM1prZOjObWcfnt5nZajNbaWavmtmAyIfagH79lNBFpN1rNKGbWRLwEDAZGAZMN7NhNUb7EMh3zo0A/gL8Z6QDbVBODmzdCuXlUV2siEhb0pQa+nhgnXNug3OuDJgHTA0fwTn3mnOuJHj7HpAT2TAb0a+fv2J069aoLlZEpC1pSkLvB3wZ9r4wGFaffwFeaklQR6xfEI6aXUSkHYvoQVEz+x6QDzxQz+fXmtkyM1u2ffv2yC04J9ghKCyM3DxFROJMUxL6ZqB/2PucYNhhzOxM4C5ginPuYF0zcs494pzLd87l9+zZsznx1k01dBGRJiX0pcAgM8szs47ApcD88BHMbDTwG3wy/zryYTYiOxs6dlRCF5F2rdGE7pwrB24EFgKfAM845wrM7D4zmxKM9gCQDvzZzFaY2fx6Ztc6zHwtXU0uItKOJTdlJOfcAmBBjWH3hL0+M8JxHTmdiy4i7VxiXCkKSugi0u4lTkLPyfFNLupGV0TaqcRJ6P36QWmpv8eoiEg7lDgJPS/PP3/ySWzjEBGJkcRJ6KedBklJ8L//G+tIRERiInESevfucOKJsGBB4+OKiCSgxEnoAOecAx98oE66RKRdSqyEPnmyf1azi4i0Q4mV0EeOhKOOgoULYx2JiEjUJVZCN/Pt6MuXxzoSEZGoS6yEDr6Wvm4d7NsX60hERKIqMRO6c/Dxx7GOREQkquI2od91Vz3HPkeO9M8ffRTVeEREYi1uE/qcOfDkk3V8MGAAdO2qhC4i7U5cJnTnoKQE1q+v40MzGDFCCV1E2p24TOhlZVBZWU9CB9/ssnKlH0lEpJ2Iy4S+f79/3rmzns4VR470I61eHdW4RERiKS4TeklJ9es6a+lnnQUZGXD11b46LyLSDiRmQu/fH373O3j/fbjzzqjFJSISS4mZ0AGmTfM19P/+b9iwISpxiYjEUuImdIB/+zdITvbPIiIJLq4TenKyv8q/Xn37wg9+AH/4A3z6aVRiExGJlbhO6EOHNlJDB7j9dn9u+hNPtHZYIiIxFdcJffhw2LwZDhxoYOQ+feDb34a5c3VeuogktLhO6Mce65+/+qqRCS6/HL74At56q1XjEhGJpbhM6KELiwYM8M/btzcywdSpkJ4OTz3VqnGJiMRSXCb0UA29yQm9Sxef1J97DsrLWzU2EZFYieuE3r+/f240oQOcfz4UFcG777ZaXCIisdSkhG5mZ5vZWjNbZ2Yz6/h8opl9YGblZjYt8mEerqTEV7p79fLvm5TQzzoLOnaEv/0Nbr0VzjuvVWMUEYm25MZGMLMk4CHgW0AhsNTM5jvnwnu++gKYAdzeGkHWFEroaWmQmtrEhJ6RAWec4bsE2LULOnTwjfFpaa0er4hINDSlhj4eWOec2+CcKwPmAVPDR3DObXTOrQSicl5gKKGbQc+esGNHEyecMsUn85QUfwrjihWtGqeISDQ1JaH3A74Me18YDDtiZnatmS0zs2Xbm1StrlsooYNP6E2e1QUX+KuRHnvMv1++vNkxiIi0NVE9KOqce8Q5l++cy+/Zs2ez59PshN6nD3zyiT8vvU8fWLas2TGIiLQ1TUnom4H+Ye9zgmEx0+yEHm7sWNXQRSShNCWhLwUGmVmemXUELgXmt25YDdu/vzqhZ2c3M6Hn58OaNbBvX0RjExGJlUYTunOuHLgRWAh8AjzjnCsws/vMbAqAmY0zs0LgYuA3ZlbQmkHXrKHv399Ify51GTtWB0ZFJKE0etoigHNuAbCgxrB7wl4vxTfFREVJSfXZhqGm+O3b4eijj2Am48f7/ndnz4aTTvKnMYqIxLG4zGI1a+jQjGaX3r19Mv/b3+AXv4hofCIisdCkGnpbU1dCb/K56OFuugmWLIG77vLV++99L2IxiohEW8Ik9GYdGDXz56Rv3QozZviuAb773UiFKSISVXHX5HLokH9EJKGD7zvg+edhwgS49FJ/U2kRkTgUdwk9dDZLKKF37QpJSS1I6OD7eXnlFd/F7q23QkEBLFzoe2g8dKjFMYuIREPcJfRQ17mhhN6hgz8Xfdu2Fs64c2f47W/96TMzZ8JVV/kDpu+808IZi4hER9wl9NDdisI7STz++Ahd9JmVBT/8IbzwAmzZ4k9rfPHFCMxYRKT1xV1Cr1lDB5g0CVauhJ07I7CA227zDfM33+xn/MILEZipiEjrS4iEftpp4BwsXhyBBWRnw+efwy9/6W+C8cknsGFDBGYsItK6EiKhjx/vT1Z5/fUILSQtzZ/SeO65/v1f/xqhGYuItJ6ESOidOvmr9994I8IL+8Y3YOJE+OlP/Vkw+/fDqlXw5psRXpCISMslREIH39z90Uf+DnMvvgi//jWUl0dggX/9q0/s3/oWpKfD8OE+yb//fgRmLiISOXF3pWh9Cf2KK+BPf4J/+ZfqYTk5EbgXdFYWLFoEv/89VFT4PmCuvRaefdZfjCQi0kbEbQ295r2dBwzw1wO9+y784x/+tqERaxnp1Qtuvx1+/GPfRcAZZ8Bzz/kjsSIibUTcJvSaNXTwxzFPOAHOPNPfv6LVmrovuADWrYM774Ru3XynXqtX+882bvTt7CIiURZ3CX3SJPiv//IXdjbk1FP9LUMbuvFFsyvYU6f6rccvfuF7afz73/1WZPNmfw7l+PG6vZ2IRF3cJfSxY+GWW3z/LQ055RTfDcuSJVBa6jtRnDABXn3Vf/7VV/6U87lzmxFEnz4wfTpMm+YPji5a5PseyM+HL76AzEyYMsXX4kVEoiTuEnpTnXyyf37iCZg8Gf78Z/jyS1+R/sMf4OGH/ZWlt9/ezNuKzp3rZ9q5s9/K3Hyz74b3mmvg5Zf9rsGYMc3cYoiIHDlzMTqwl5+f75YtW9aqyxgxAj7+2J+n/uijcPHFvslm48bqE1YKCuCee+Df/q2FCyspgccfh8sv9zX0L76Ayy6Dt97ybezf+hb06AHf/Gbj7UUiIvUws+XOufw6P0vkhP7hh7B+vc+lXbv6YUuX+iZu8M0vv/mN7w590aLqWn3ElJfDz38OP/uZvyE1+NNzrrvOH1DNyqoe96WXIC8Phg6NcBAikkjabUKvz803w4oVvquAnTvhxBNh1y646CJfiZ41y9+8KGK2bfPtOhs2+PPZ//hHPzwvz99Uo1Mnv5vQubPvQ+af/9kH9OGHcPrpvl8DERGU0Bv16adw1lk+5+7Y4e9r8Yc/1D7XPWJWrfLt78uWwYIFftgll0BRke9iICPDN+FUVMBRR8H99/vz3wsK/NHgY49tpcBEpK1TQj8C/+//+XtHAwwc6JvFJ06s/rykxD+ysyO0wOXLfTvQNdf4UyH/8Q/f3UCPHjBunK+xv/22P0VnyRK/6/Dww74WX17udzPGjDm8+UZEEpYS+hH6xz985fnxx30ryejRUFYGhYW+iSYpCd57z1ekb77Z37XurLNaKZiKCt8O/4tf+C4HCgNVICEAABAqSURBVAp84/8JJ/hdilWr/FVWU6f6y2WHD/d9HuzY4Q/Oduniz9Hs2xdGjar7iiwRiRtK6M20d6/vaHHdOt+VQL9+0L+/rzSPHOmPc772mh935kz4939vxWAqK/399srL4ZFHfBDOwV13+Y7gX3vN32WpoXugJiXBsGG+k7EDB3ybUlmZn8/3v+83BEuW+KPI48b5ef35z7Bnjz+RP2K7JSLSXEroEfbgg75WDv6q1dWr/WmRDzxQnR/vuMNvBKKqvNwHs3Wrv+vS3r2+y9++ff1plMuW+SaeQ4f8gdj9+/3zli2+q8pwmZl+A7Brl3+fnOzPwMnN9bsmW7b43ZUuXfzpQaed5sd9/31/EPjqq/3eQnGxP6jbt69vLnLO7+ps2uTPK+3UyW8xMzP9FWCbNvm9j/T02t+vstLPL3TKUkhJCRw8CN27t0qxirQlSugRVlrqK7pZWb7pBXyLR/jtR8eM8fnn4EF/UekVV/jz3hcv9m3zX3/t2+ovuQR+9KPYfI8qzsHChX5rNGGCv+3eihU+4V98sd81mTfPn9RfWOiTau/evsa+Z4+/kXZozyAtzT++/vrwZXTp4gtt/frqjURSkt/rqLlXkZnp27A6dvTHFULjvPaa31j16OE3BGVlvoD37fPjTZ3qNywHDvh7Enbq5H+IDh38dIWF/irf5GS/gUtO9huOtDT/HP46JaV6LyY72//YZj72zz7zsXfv7tvkdu3yy8jK8k1ku3b5jVLXrn4jOnCg/+7O+esSNm3yzWNjx/pyfPttP6xDB3/1cceOvpyOPrp6uaHfadcuvwHLyKjesK1e7cvmtNP8DXZr2rfP/x7l5f6xd6//DhUVvuO5k07yfRKFrw/79/vfOTOz4bMDDh2C3bt9mYXOxtq3z78387F27OjLui6Vlf63SU31v2sk7N3rnzMyqsuupooK/6jvdLaSEn/WWX3Tx1CLE7qZnQ38N5AE/NY594san3cCfg+MBYqAS5xzGxuaZzwndPD/q06dqpuk9+6FOXOq71o3c6Y/KxGqb7yRllZ9k2vw68uBA3DvvXDMMX6eycn+2qSMDP+/WrnS/29zc6P69Y7Mrl2wZo1PPnl5PvDnnvN/9IwMvwVcscK3/w8a5NurQs075eW+Jr9/v//yvXr5U4yWLvXzca76HP5x43wS3LTJT9exo/8RsrN98nn0UX+mEPiEeeBA9YYlKckn86+/9vPr188/hxJXRDrPj4CUFJ9oQt85KcmXYUaGL8/i4upxu3XzCTV8pRo2zO+dlZT4sigq8hvdhnTo4Mu9QwefjPftq15+crL/vcI3nKFHZaW//DpUduEb6D59/LqwZIlf8UeP9tOXlvoN8dat/rVz1dMPHOg3YuD7Raqs9PNMTvbPNV936ODH27LFvw+VXaiMUlL8RiIry2+Yduzwn6em+g1xWZn/3l26VM87OdmX15df+nI87jgfZ6hM+vf36/vWrf77ZWb677tnT/XGtm9fv7EvL6/ecIRe79vnp509G668slmrSIsSupklAZ8C3wIKgaXAdOfc6rBxvg+McM5db2aXAhc45y5paL7xntCPxMaN8NRTfr075xy/Lu3ZAzfe6M9GnD//8PH79PEXPxUU+Ipahw6+8tmpk18vunTxj6OP9hXQN96A7dt9r769e1evl8nJ/r/Uowf8z//4ivT3vudz6o4dfh3u1w+GDPHr2oEDfv7Z2T7Gd9/1/+XjjvPr6gsv+PVx+nQ/3717fU4N5dWOHf1/pKzMV9AqK/3rUAXv4EE/Xl2VnspK/18oLa3+L6xe7ZcRqvwOHHj4Kfnl5f6/kZLip+lQWQ779rF3fxJLPsngUJkjL7OIvFzHwc7d+GxjClndKsjpW0lqhm8PO3Ag2GEoKyO5rISUg/tIZx+VBw+xqSid7NR9dC/bRuGnJawuzGRHeTcmnpfJ+k3JLF4MQ/IzGHdGBnkDKrGdRT7YtDRYvJgvNlWyYOeJDOuykRM7ryClQwW7Bo3n7aKhvP9KMf1KPmVM2qdkTxxGzim5dNyznaJHnqU0OZ3U4YNI3bYJ21lExd79/pGWSUX/XMo7Z1Cxay8UFpLdrZx9OUNZmX0GqcveonLlKgp3pNIjvYy+vSvo3KMzX6QOZltSX7p3rSTvqFKyenZgVcWxHKjoSFrxVnLWv4F9vY0d+ztT1KEnXbt3YFjeAZK7plFYsId1S3cyqs82+vUsA6D0UBLr9vbiw125fFg+nMouaVw3ZhnHdgk2tN26sWvpOr747CC7jz+F3Tsr2bN+B3tSsjkqcz8n9NpAv9wUyjtnsHlvBsk5feheWUTaqvc5WLidrQe783X3IXRKqSSjw346WylrdvVm2a6BfLznaMZkfMaUHm/jKirp2jeNkuyjefaz4Wzek8Hm/d343y+H0TP9AJcO/pABSYUc49YxLvlDuvTOoNQ6s2F7Bvt7D6S0YyY7C/fz8qahlJYncU3eq+R1+oryTmkcGvANyjdtpnxjIWWpmXzh+rO3vAunHXyZfj3L2N8zl7VrHMml+zi6yw4yeqSwKy2HL8r7sn9rMZmlXzMkfTOpKRWQlERlUgq7XVcqU7uQNSAd+95lvsOpZmhpQj8RmOWcOyt4/xMA59y/h42zMBjnXTNLBrYCPV0DM29PCb0hFRW+JSOUeD/7DO6+21ckBwyA73wH1q711yKlpfnkVVLiK2U7dvh5JCX5BNpYRSw3129coq1Tp+pKSnLy4ZVQMx9/aWn1+KG985qV5lBFcs+e6vmFKpJHqkcPn8wb6o0zJLQn1ZDMTL+xCVVek5L8yUWhf0Byst/YhoaZHd7bZ3Ky3yht39687xMN3bv7ymh430edO1c3LYYqz2aH/5516dzZ/37hrW0192Dr0rNn/WXUpYvfmz3zTN+iVvOWlKFzASoqak+XlHT4zk9Dav52RyolBR56yJ+p3BwNJfSm3LGoH/Bl2PtCoOateqrGcc6Vm9keIAvYUSOQa4FrAY4O7Vq1c0lJ/mzCkKwsf9pkTbNn1x62fbu/mHTMGP9nW7nS12hDe3eh5tLCQt+Hzdixvta9f7//Y1RU+AS/bp2vXaem+j/l9u2+ln7qqb6l5Isv/B8wdNHqX/7iV8quXf0fMtSUXVbmk3dKil9uaC+hqKi6uTrUuhHaa66srN7rSE/302/d6r/f6NG+PCor/QZuzRq/l9O1q19G6Myjigp/fDakUyff8WVamt/T2LCh+pjurl3++2zZ4j/PyvItF6GWgkOHfIyVlX4DuG2bH3fIEH89V2amb67u3dvfQ3z9et9MvmqVnzbUSlRR4fegpk3zcS9b5lsHBg/25Tp+vE/uBQW+fD791Jd7aBmlpT75OFddVjVbHJzz8aWm+nUolKj69/flsXVrdQtA377+u69b5ysCxx/vv3dxsW9dMPNlkZXlP1+71s+/Vy+/Z7RkiV9XUlL8ujNggP99Bg/2833qqeoWjYoKv5eZm+s3nF27+mVlZsLnn/vWtA0b/Dp3zDF+OUVF/rv06OFj7dXLr0/FxX59PeYYv/727OnX8/fe87/z7t1+/Zk61d8pMlxxsZ9vQYH/n+zc6X/zY4/1MaWm+vUudFryc89Vt/ylpBz+3K+fX96iRb5CkZbm93QrKvz/a98+//1yc/16XFTkK2ehDZaZLwMzvz6NGNGcbNG4ptTQpwFnO+euDt5fDkxwzt0YNs6qYJzC4P36YJwddc0TVEMXEWmOhmroTek+dzPQP+x9TjCsznGCJpeu+IOjIiISJU1J6EuBQWaWZ2YdgUuBGofxmA+EDtlOAxY11H4uIiKR12gbetAmfiOwEH/a4u+ccwVmdh+wzDk3H3gMeMrM1gE78UlfRESiqCkHRXHOLQAW1Bh2T9jrUuDiyIYmIiJHImFvQSci0t4ooYuIJAgldBGRBKGELiKSIGLW26KZbQc2NXPybGpchdqGtNXYFNeRUVxHrq3GlmhxDXDO9azrg5gl9JYws2X1XSkVa201NsV1ZBTXkWursbWnuNTkIiKSIJTQRUQSRLwm9EdiHUAD2mpsiuvIKK4j11ZjazdxxWUbuoiI1BavNXQREalBCV1EJEHEXUI3s7PNbK2ZrTOzmTGMo7+ZvWZmq82swMxuDobPMrPNZrYieJwTg9g2mtnHwfKXBcN6mNk/zOyz4Ll7lGMaElYmK8xsr5ndEqvyMrPfmdnXwc1ZQsPqLCPz5gTr3EozGxPluB4wszXBsp8zs27B8FwzOxBWdr+Oclz1/nZm9pOgvNaa2VmtFVcDsT0dFtdGM1sRDI9KmTWQH1p3HXPOxc0D333vemAg0BH4CBgWo1iOAsYErzPwN9IeBswCbo9xOW0EsmsM+09gZvB6JvAfMf4dtwIDYlVewERgDLCqsTICzgFeAgw4AXg/ynF9G0gOXv9HWFy54ePFoLzq/O2C/8FHQCcgL/jPJkUzthqf/1/gnmiWWQP5oVXXsXiroY8H1jnnNjjnyoB5wNRYBOKc2+Kc+yB4XQx8gr+3als1FXgyeP0kcH4MY/kmsN4519wrhVvMObcY33d/uPrKaCrwe+e9B3Qzs6OiFZdz7mXnXOiW2e/h7xoWVfWUV32mAvOccwedc58D6/D/3ajHZmYGfBf4U2stv56Y6ssPrbqOxVtCr+uG1TFPomaWC4wG3g8G3RjsNv0u2k0bAQe8bGbLzd+YG6C3c25L8Hor0DsGcYVcyuF/sFiXV0h9ZdSW1rur8DW5kDwz+9DM3jCzU2MQT12/XVsqr1OBbc65z8KGRbXMauSHVl3H4i2htzlmlg48C9zinNsL/Ao4BhgFbMHv7kXbKc65McBk4AdmNjH8Q+f38WJyvqr52xhOAf4cDGoL5VVLLMuoPmZ2F1AOzA0GbQGOds6NBm4D/mhmmVEMqU3+djVM5/DKQ1TLrI78UKU11rF4S+hNuWF11JhZCv7Hmuuc+yuAc26bc67COVcJPEor7mrWxzm3OXj+GnguiGFbaBcueP462nEFJgMfOOe2BTHGvLzC1FdGMV/vzGwGcB5wWZAICJo0ioLXy/Ft1YOjFVMDv13Mywuqblh/IfB0aFg0y6yu/EArr2PxltCbcsPqqAja5h4DPnHO/TJseHi71wXAqprTtnJcaWaWEXqNP6C2isNv5H0l8LdoxhXmsBpTrMurhvrKaD5wRXAmwgnAnrDd5lZnZmcDdwBTnHMlYcN7mllS8HogMAjYEMW46vvt5gOXmlknM8sL4loSrbjCnAmscc4VhgZEq8zqyw+09jrW2kd7I/3AHw3+FL9lvSuGcZyC311aCawIHucATwEfB8PnA0dFOa6B+DMMPgIKQmUEZAGvAp8BrwA9YlBmaUAR0DVsWEzKC79R2QIcwrdX/kt9ZYQ/8+ChYJ37GMiPclzr8O2rofXs18G4FwW/8QrgA+A7UY6r3t8OuCsor7XA5Gj/lsHwJ4Dra4wblTJrID+06jqmS/9FRBJEvDW5iIhIPZTQRUQShBK6iEiCUEIXEUkQSugiIglCCV1EJEEooYuIJIj/D97YAwcaA6W4AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(572,) (144,)\n",
            "Train data RMSE:  0.07027424883608963\n",
            "Train data MSE:  0.0049384700494766445\n",
            "Train data MAE:  0.032370704789993564\n",
            "-------------------------------------------------------------------------------------\n",
            "Test data RMSE:  0.025594983440363824\n",
            "Test data MSE:  0.0006551031773124983\n",
            "Test data MAE:  0.02111175823155326\n",
            "Train data R2 score: -0.0647949383601405\n",
            "Test data R2 score: -1.656418937889823\n",
            "Train data MGD:  0.003950590540421976\n",
            "Test data MGD:  0.000638449272064341\n",
            "----------------------------------------------------------------------\n",
            "Train data MPD:  0.004379183387391765\n",
            "Test data MPD:  0.0006465901933728526\n",
            "(716, 15, 191) (716,)\n",
            "Epoch 1/200\n",
            "18/18 [==============================] - 3s 64ms/step - loss: 2.2697 - accuracy: 0.0000e+00 - val_loss: 1.8324 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.9628 - accuracy: 0.0000e+00 - val_loss: 0.6356 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.4026 - accuracy: 0.0000e+00 - val_loss: 0.1758 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.2190 - accuracy: 0.0000e+00 - val_loss: 0.0616 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.1637 - accuracy: 0.0000e+00 - val_loss: 0.0397 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.1897 - accuracy: 0.0000e+00 - val_loss: 0.0343 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.1752 - accuracy: 0.0000e+00 - val_loss: 0.0355 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.1461 - accuracy: 0.0000e+00 - val_loss: 0.0386 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.1527 - accuracy: 0.0000e+00 - val_loss: 0.0369 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.1115 - accuracy: 0.0000e+00 - val_loss: 0.0318 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.1177 - accuracy: 0.0000e+00 - val_loss: 0.0315 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.1287 - accuracy: 0.0000e+00 - val_loss: 0.0279 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0982 - accuracy: 0.0000e+00 - val_loss: 0.0306 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.1014 - accuracy: 0.0000e+00 - val_loss: 0.0248 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0902 - accuracy: 0.0000e+00 - val_loss: 0.0228 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/200\n",
            "18/18 [==============================] - 1s 45ms/step - loss: 0.0966 - accuracy: 0.0000e+00 - val_loss: 0.0195 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0930 - accuracy: 0.0000e+00 - val_loss: 0.0192 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0876 - accuracy: 0.0000e+00 - val_loss: 0.0208 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0863 - accuracy: 0.0000e+00 - val_loss: 0.0182 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0899 - accuracy: 0.0000e+00 - val_loss: 0.0168 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0950 - accuracy: 0.0000e+00 - val_loss: 0.0171 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0738 - accuracy: 0.0000e+00 - val_loss: 0.0195 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0694 - accuracy: 0.0000e+00 - val_loss: 0.0169 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0657 - accuracy: 0.0000e+00 - val_loss: 0.0158 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0648 - accuracy: 0.0000e+00 - val_loss: 0.0158 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0527 - accuracy: 0.0000e+00 - val_loss: 0.0128 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0701 - accuracy: 0.0000e+00 - val_loss: 0.0117 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0614 - accuracy: 0.0000e+00 - val_loss: 0.0116 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0486 - accuracy: 0.0000e+00 - val_loss: 0.0118 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0622 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0578 - accuracy: 0.0000e+00 - val_loss: 0.0100 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0443 - accuracy: 0.0000e+00 - val_loss: 0.0107 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0549 - accuracy: 0.0000e+00 - val_loss: 0.0085 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0515 - accuracy: 0.0000e+00 - val_loss: 0.0099 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0442 - accuracy: 0.0000e+00 - val_loss: 0.0084 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0403 - accuracy: 0.0000e+00 - val_loss: 0.0082 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/200\n",
            "18/18 [==============================] - 1s 52ms/step - loss: 0.0450 - accuracy: 0.0000e+00 - val_loss: 0.0087 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0456 - accuracy: 0.0000e+00 - val_loss: 0.0073 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0427 - accuracy: 0.0000e+00 - val_loss: 0.0079 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0349 - accuracy: 0.0000e+00 - val_loss: 0.0069 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0424 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0378 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0402 - accuracy: 0.0000e+00 - val_loss: 0.0067 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0339 - accuracy: 0.0000e+00 - val_loss: 0.0079 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0403 - accuracy: 0.0000e+00 - val_loss: 0.0056 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0354 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0373 - accuracy: 0.0000e+00 - val_loss: 0.0062 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0347 - accuracy: 0.0000e+00 - val_loss: 0.0049 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0371 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0309 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0274 - accuracy: 0.0000e+00 - val_loss: 0.0065 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0319 - accuracy: 0.0000e+00 - val_loss: 0.0050 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0283 - accuracy: 0.0000e+00 - val_loss: 0.0049 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0236 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0268 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0243 - accuracy: 0.0000e+00 - val_loss: 0.0052 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0247 - accuracy: 0.0000e+00 - val_loss: 0.0050 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0246 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0287 - accuracy: 0.0000e+00 - val_loss: 0.0052 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0278 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0277 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0233 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0203 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0244 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0243 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0193 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0204 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0186 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/200\n",
            "18/18 [==============================] - 1s 45ms/step - loss: 0.0196 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0200 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0188 - accuracy: 0.0000e+00 - val_loss: 0.0048 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0197 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0210 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0187 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0185 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0179 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0178 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0199 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0165 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0145 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
            "Epoch 81/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0160 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0170 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0157 - accuracy: 0.0000e+00 - val_loss: 0.0051 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0175 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0143 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\n",
            "Epoch 86/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0156 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0138 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0148 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0148 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0135 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0157 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
            "Epoch 92/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0145 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0116 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0142 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0150 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0137 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
            "Epoch 97/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0149 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
            "Epoch 98/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0117 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0116 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
            "Epoch 100/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0130 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
            "Epoch 101/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0106 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
            "Epoch 102/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0117 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
            "Epoch 103/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0108 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
            "Epoch 104/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0109 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
            "Epoch 105/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0100 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
            "Epoch 106/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0109 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
            "Epoch 107/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0099 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
            "Epoch 108/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0109 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
            "Epoch 109/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0103 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
            "Epoch 110/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0099 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
            "Epoch 111/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0094 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
            "Epoch 112/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0097 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
            "Epoch 113/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0116 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
            "Epoch 114/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0093 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
            "Epoch 115/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
            "Epoch 116/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0095 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
            "Epoch 117/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
            "Epoch 118/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0105 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
            "Epoch 119/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0097 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
            "Epoch 120/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0088 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
            "Epoch 121/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0106 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
            "Epoch 122/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0076 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
            "Epoch 123/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0105 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
            "Epoch 124/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0097 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
            "Epoch 125/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0090 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
            "Epoch 126/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0090 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
            "Epoch 127/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0078 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\n",
            "Epoch 128/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0080 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
            "Epoch 129/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0090 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
            "Epoch 130/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0080 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\n",
            "Epoch 131/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0071 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
            "Epoch 132/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0078 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
            "Epoch 133/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0080 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
            "Epoch 134/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
            "Epoch 135/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0072 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
            "Epoch 136/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0089 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
            "Epoch 137/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0060 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
            "Epoch 138/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0080 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
            "Epoch 139/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0071 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
            "Epoch 140/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0070 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
            "Epoch 141/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0075 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\n",
            "Epoch 142/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0058 - accuracy: 0.0000e+00 - val_loss: 0.0049 - val_accuracy: 0.0000e+00\n",
            "Epoch 143/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0077 - accuracy: 0.0000e+00 - val_loss: 0.0052 - val_accuracy: 0.0000e+00\n",
            "Epoch 144/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0062 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
            "Epoch 145/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0069 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\n",
            "Epoch 146/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0077 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
            "Epoch 147/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0074 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
            "Epoch 148/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0068 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
            "Epoch 149/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0095 - accuracy: 0.0000e+00 - val_loss: 0.0052 - val_accuracy: 0.0000e+00\n",
            "Epoch 150/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0062 - accuracy: 0.0000e+00 - val_loss: 0.0051 - val_accuracy: 0.0000e+00\n",
            "Epoch 151/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0065 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
            "Epoch 152/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0071 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
            "Epoch 153/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0067 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\n",
            "Epoch 154/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0059 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\n",
            "Epoch 155/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0076 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
            "Epoch 156/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0079 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
            "Epoch 157/200\n",
            "18/18 [==============================] - 1s 52ms/step - loss: 0.0062 - accuracy: 0.0000e+00 - val_loss: 0.0051 - val_accuracy: 0.0000e+00\n",
            "Epoch 158/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0071 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
            "Epoch 159/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0059 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\n",
            "Epoch 160/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0059 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\n",
            "Epoch 161/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0060 - accuracy: 0.0000e+00 - val_loss: 0.0049 - val_accuracy: 0.0000e+00\n",
            "Epoch 162/200\n",
            "18/18 [==============================] - 1s 52ms/step - loss: 0.0066 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
            "Epoch 163/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0066 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
            "Epoch 164/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0064 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
            "Epoch 165/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0061 - accuracy: 0.0000e+00 - val_loss: 0.0049 - val_accuracy: 0.0000e+00\n",
            "Epoch 166/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0058 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\n",
            "Epoch 167/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0066 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
            "Epoch 168/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0066 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
            "Epoch 169/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0055 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
            "Epoch 170/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0056 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
            "Epoch 171/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0057 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
            "Epoch 172/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0050 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
            "Epoch 173/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0063 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
            "Epoch 174/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0061 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\n",
            "Epoch 175/200\n",
            "18/18 [==============================] - 1s 53ms/step - loss: 0.0067 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
            "Epoch 176/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0065 - accuracy: 0.0000e+00 - val_loss: 0.0049 - val_accuracy: 0.0000e+00\n",
            "Epoch 177/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0052 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\n",
            "Epoch 178/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0056 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
            "Epoch 179/200\n",
            "18/18 [==============================] - 1s 52ms/step - loss: 0.0056 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
            "Epoch 180/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0067 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
            "Epoch 181/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0055 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
            "Epoch 182/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0064 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\n",
            "Epoch 183/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0054 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
            "Epoch 184/200\n",
            "18/18 [==============================] - 1s 52ms/step - loss: 0.0055 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
            "Epoch 185/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0056 - accuracy: 0.0000e+00 - val_loss: 0.0048 - val_accuracy: 0.0000e+00\n",
            "Epoch 186/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0053 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
            "Epoch 187/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0056 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
            "Epoch 188/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0052 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_accuracy: 0.0000e+00\n",
            "Epoch 189/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0056 - accuracy: 0.0000e+00 - val_loss: 0.0051 - val_accuracy: 0.0000e+00\n",
            "Epoch 190/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0053 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
            "Epoch 191/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0055 - accuracy: 0.0000e+00 - val_loss: 0.0051 - val_accuracy: 0.0000e+00\n",
            "Epoch 192/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0051 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
            "Epoch 193/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0055 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
            "Epoch 194/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
            "Epoch 195/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0051 - accuracy: 0.0000e+00 - val_loss: 0.0050 - val_accuracy: 0.0000e+00\n",
            "Epoch 196/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0050 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
            "Epoch 197/200\n",
            "18/18 [==============================] - 1s 54ms/step - loss: 0.0053 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
            "Epoch 198/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0050 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
            "Epoch 199/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
            "Epoch 200/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0058 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(572,) (144,)\n",
            "Train data RMSE:  0.0654840527851064\n",
            "Train data MSE:  0.004288161169162601\n",
            "Train data MAE:  0.04934675598850379\n",
            "-------------------------------------------------------------------------------------\n",
            "Test data RMSE:  0.062401176531053475\n",
            "Test data MSE:  0.003893906832459699\n",
            "Test data MAE:  0.04734249339585453\n",
            "Train data R2 score: -1.4528958693023006\n",
            "Test data R2 score: -2.573064783443722\n",
            "Train data MGD:  0.004652794773589776\n",
            "Test data MGD:  0.004214111829874949\n",
            "----------------------------------------------------------------------\n",
            "Train data MPD:  0.004458828219645971\n",
            "Test data MPD:  0.004048315963672357\n",
            "(716, 15, 191) (716,)\n",
            "Epoch 1/200\n",
            "18/18 [==============================] - 4s 67ms/step - loss: 2.6834 - accuracy: 0.0000e+00 - val_loss: 1.2015 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 1.2744 - accuracy: 0.0000e+00 - val_loss: 0.3462 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.6071 - accuracy: 0.0000e+00 - val_loss: 0.0543 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.2474 - accuracy: 0.0000e+00 - val_loss: 0.0210 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.2115 - accuracy: 0.0000e+00 - val_loss: 0.0367 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.1607 - accuracy: 0.0000e+00 - val_loss: 0.0444 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.1647 - accuracy: 0.0000e+00 - val_loss: 0.0463 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1910 - accuracy: 0.0000e+00 - val_loss: 0.0428 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.1453 - accuracy: 0.0000e+00 - val_loss: 0.0418 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.1393 - accuracy: 0.0000e+00 - val_loss: 0.0379 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1220 - accuracy: 0.0000e+00 - val_loss: 0.0309 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/200\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.1193 - accuracy: 0.0000e+00 - val_loss: 0.0288 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0994 - accuracy: 0.0000e+00 - val_loss: 0.0263 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1035 - accuracy: 0.0000e+00 - val_loss: 0.0232 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0979 - accuracy: 0.0000e+00 - val_loss: 0.0239 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0765 - accuracy: 0.0000e+00 - val_loss: 0.0267 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0757 - accuracy: 0.0000e+00 - val_loss: 0.0248 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0693 - accuracy: 0.0000e+00 - val_loss: 0.0251 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0737 - accuracy: 0.0000e+00 - val_loss: 0.0235 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0728 - accuracy: 0.0000e+00 - val_loss: 0.0216 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0613 - accuracy: 0.0000e+00 - val_loss: 0.0206 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0662 - accuracy: 0.0000e+00 - val_loss: 0.0202 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0612 - accuracy: 0.0000e+00 - val_loss: 0.0195 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0590 - accuracy: 0.0000e+00 - val_loss: 0.0216 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0634 - accuracy: 0.0000e+00 - val_loss: 0.0224 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0617 - accuracy: 0.0000e+00 - val_loss: 0.0199 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0482 - accuracy: 0.0000e+00 - val_loss: 0.0191 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0449 - accuracy: 0.0000e+00 - val_loss: 0.0192 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0450 - accuracy: 0.0000e+00 - val_loss: 0.0188 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0514 - accuracy: 0.0000e+00 - val_loss: 0.0183 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0432 - accuracy: 0.0000e+00 - val_loss: 0.0205 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0454 - accuracy: 0.0000e+00 - val_loss: 0.0188 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0450 - accuracy: 0.0000e+00 - val_loss: 0.0206 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0378 - accuracy: 0.0000e+00 - val_loss: 0.0200 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0454 - accuracy: 0.0000e+00 - val_loss: 0.0172 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0396 - accuracy: 0.0000e+00 - val_loss: 0.0177 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0362 - accuracy: 0.0000e+00 - val_loss: 0.0189 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0401 - accuracy: 0.0000e+00 - val_loss: 0.0185 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0371 - accuracy: 0.0000e+00 - val_loss: 0.0172 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0372 - accuracy: 0.0000e+00 - val_loss: 0.0165 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0355 - accuracy: 0.0000e+00 - val_loss: 0.0180 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0350 - accuracy: 0.0000e+00 - val_loss: 0.0174 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0332 - accuracy: 0.0000e+00 - val_loss: 0.0180 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0301 - accuracy: 0.0000e+00 - val_loss: 0.0195 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0346 - accuracy: 0.0000e+00 - val_loss: 0.0178 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0264 - accuracy: 0.0000e+00 - val_loss: 0.0154 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0397 - accuracy: 0.0000e+00 - val_loss: 0.0166 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0282 - accuracy: 0.0000e+00 - val_loss: 0.0159 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0272 - accuracy: 0.0000e+00 - val_loss: 0.0145 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0302 - accuracy: 0.0000e+00 - val_loss: 0.0165 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0254 - accuracy: 0.0000e+00 - val_loss: 0.0150 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0238 - accuracy: 0.0000e+00 - val_loss: 0.0146 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0279 - accuracy: 0.0000e+00 - val_loss: 0.0157 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0257 - accuracy: 0.0000e+00 - val_loss: 0.0150 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0261 - accuracy: 0.0000e+00 - val_loss: 0.0150 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0226 - accuracy: 0.0000e+00 - val_loss: 0.0134 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0271 - accuracy: 0.0000e+00 - val_loss: 0.0158 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0232 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0218 - accuracy: 0.0000e+00 - val_loss: 0.0092 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0235 - accuracy: 0.0000e+00 - val_loss: 0.0095 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0248 - accuracy: 0.0000e+00 - val_loss: 0.0096 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0191 - accuracy: 0.0000e+00 - val_loss: 0.0081 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0179 - accuracy: 0.0000e+00 - val_loss: 0.0081 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0215 - accuracy: 0.0000e+00 - val_loss: 0.0093 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0230 - accuracy: 0.0000e+00 - val_loss: 0.0085 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0185 - accuracy: 0.0000e+00 - val_loss: 0.0079 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0176 - accuracy: 0.0000e+00 - val_loss: 0.0076 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0220 - accuracy: 0.0000e+00 - val_loss: 0.0079 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0220 - accuracy: 0.0000e+00 - val_loss: 0.0083 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0215 - accuracy: 0.0000e+00 - val_loss: 0.0074 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0204 - accuracy: 0.0000e+00 - val_loss: 0.0078 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0187 - accuracy: 0.0000e+00 - val_loss: 0.0086 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0171 - accuracy: 0.0000e+00 - val_loss: 0.0077 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0194 - accuracy: 0.0000e+00 - val_loss: 0.0074 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0179 - accuracy: 0.0000e+00 - val_loss: 0.0071 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0191 - accuracy: 0.0000e+00 - val_loss: 0.0070 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0196 - accuracy: 0.0000e+00 - val_loss: 0.0072 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0177 - accuracy: 0.0000e+00 - val_loss: 0.0069 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0162 - accuracy: 0.0000e+00 - val_loss: 0.0064 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0135 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_accuracy: 0.0000e+00\n",
            "Epoch 81/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0157 - accuracy: 0.0000e+00 - val_loss: 0.0070 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0159 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0223 - accuracy: 0.0000e+00 - val_loss: 0.0076 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0141 - accuracy: 0.0000e+00 - val_loss: 0.0064 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/200\n",
            "18/18 [==============================] - 1s 53ms/step - loss: 0.0142 - accuracy: 0.0000e+00 - val_loss: 0.0062 - val_accuracy: 0.0000e+00\n",
            "Epoch 86/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0161 - accuracy: 0.0000e+00 - val_loss: 0.0074 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0179 - accuracy: 0.0000e+00 - val_loss: 0.0081 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0158 - accuracy: 0.0000e+00 - val_loss: 0.0057 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0131 - accuracy: 0.0000e+00 - val_loss: 0.0057 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0132 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0158 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_accuracy: 0.0000e+00\n",
            "Epoch 92/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0159 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0147 - accuracy: 0.0000e+00 - val_loss: 0.0052 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0140 - accuracy: 0.0000e+00 - val_loss: 0.0064 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0099 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/200\n",
            "18/18 [==============================] - 1s 54ms/step - loss: 0.0129 - accuracy: 0.0000e+00 - val_loss: 0.0065 - val_accuracy: 0.0000e+00\n",
            "Epoch 97/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0142 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_accuracy: 0.0000e+00\n",
            "Epoch 98/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0133 - accuracy: 0.0000e+00 - val_loss: 0.0052 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0131 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\n",
            "Epoch 100/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0131 - accuracy: 0.0000e+00 - val_loss: 0.0052 - val_accuracy: 0.0000e+00\n",
            "Epoch 101/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0121 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
            "Epoch 102/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0107 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_accuracy: 0.0000e+00\n",
            "Epoch 103/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0117 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_accuracy: 0.0000e+00\n",
            "Epoch 104/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0117 - accuracy: 0.0000e+00 - val_loss: 0.0052 - val_accuracy: 0.0000e+00\n",
            "Epoch 105/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0118 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_accuracy: 0.0000e+00\n",
            "Epoch 106/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0137 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_accuracy: 0.0000e+00\n",
            "Epoch 107/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0104 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_accuracy: 0.0000e+00\n",
            "Epoch 108/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0114 - accuracy: 0.0000e+00 - val_loss: 0.0051 - val_accuracy: 0.0000e+00\n",
            "Epoch 109/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0116 - accuracy: 0.0000e+00 - val_loss: 0.0052 - val_accuracy: 0.0000e+00\n",
            "Epoch 110/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0102 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
            "Epoch 111/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_accuracy: 0.0000e+00\n",
            "Epoch 112/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0099 - accuracy: 0.0000e+00 - val_loss: 0.0051 - val_accuracy: 0.0000e+00\n",
            "Epoch 113/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0102 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\n",
            "Epoch 114/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0102 - accuracy: 0.0000e+00 - val_loss: 0.0048 - val_accuracy: 0.0000e+00\n",
            "Epoch 115/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0108 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\n",
            "Epoch 116/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0102 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\n",
            "Epoch 117/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0104 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
            "Epoch 118/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0105 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
            "Epoch 119/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0095 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
            "Epoch 120/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0110 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\n",
            "Epoch 121/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0102 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
            "Epoch 122/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
            "Epoch 123/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0090 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
            "Epoch 124/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0118 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
            "Epoch 125/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
            "Epoch 126/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
            "Epoch 127/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0088 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
            "Epoch 128/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0103 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
            "Epoch 129/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
            "Epoch 130/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0092 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
            "Epoch 131/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0129 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
            "Epoch 132/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0093 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
            "Epoch 133/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0095 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
            "Epoch 134/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
            "Epoch 135/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
            "Epoch 136/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
            "Epoch 137/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0080 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
            "Epoch 138/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0098 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
            "Epoch 139/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0076 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
            "Epoch 140/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
            "Epoch 141/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0075 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
            "Epoch 142/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
            "Epoch 143/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0093 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
            "Epoch 144/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
            "Epoch 145/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0106 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
            "Epoch 146/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0080 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 147/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0088 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
            "Epoch 148/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0094 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
            "Epoch 149/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0090 - accuracy: 0.0000e+00 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
            "Epoch 150/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0065 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
            "Epoch 151/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0077 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
            "Epoch 152/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
            "Epoch 153/200\n",
            "18/18 [==============================] - 1s 52ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
            "Epoch 154/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0074 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
            "Epoch 155/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
            "Epoch 156/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
            "Epoch 157/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0080 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
            "Epoch 158/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0074 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 159/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0075 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
            "Epoch 160/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0066 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
            "Epoch 161/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0067 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 162/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0064 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
            "Epoch 163/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0074 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 164/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0074 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 165/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
            "Epoch 166/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0072 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 167/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0069 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 168/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0072 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
            "Epoch 169/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0064 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
            "Epoch 170/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0074 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 171/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0078 - accuracy: 0.0000e+00 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
            "Epoch 172/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0073 - accuracy: 0.0000e+00 - val_loss: 0.0022 - val_accuracy: 0.0000e+00\n",
            "Epoch 173/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0075 - accuracy: 0.0000e+00 - val_loss: 0.0022 - val_accuracy: 0.0000e+00\n",
            "Epoch 174/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0078 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 175/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0064 - accuracy: 0.0000e+00 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 176/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0074 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
            "Epoch 177/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0072 - accuracy: 0.0000e+00 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 178/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0075 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 179/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0070 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 180/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 181/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0067 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 182/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
            "Epoch 183/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0063 - accuracy: 0.0000e+00 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 184/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0062 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
            "Epoch 185/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0069 - accuracy: 0.0000e+00 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 186/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0067 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 187/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0068 - accuracy: 0.0000e+00 - val_loss: 0.0022 - val_accuracy: 0.0000e+00\n",
            "Epoch 188/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0073 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
            "Epoch 189/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0065 - accuracy: 0.0000e+00 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 190/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0065 - accuracy: 0.0000e+00 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 191/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0076 - accuracy: 0.0000e+00 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 192/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0071 - accuracy: 0.0000e+00 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 193/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0070 - accuracy: 0.0000e+00 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 194/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0058 - accuracy: 0.0000e+00 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 195/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0059 - accuracy: 0.0000e+00 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 196/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0065 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
            "Epoch 197/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0067 - accuracy: 0.0000e+00 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 198/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0070 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
            "Epoch 199/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0063 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 200/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0064 - accuracy: 0.0000e+00 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(572,) (144,)\n",
            "Train data RMSE:  0.0645822617581416\n",
            "Train data MSE:  0.004170868533797118\n",
            "Train data MAE:  0.04533227742765906\n",
            "-------------------------------------------------------------------------------------\n",
            "Test data RMSE:  0.04537912666656663\n",
            "Test data MSE:  0.002059265137020298\n",
            "Test data MAE:  0.034876140840998715\n",
            "Train data R2 score: -0.3461721143993812\n",
            "Test data R2 score: -0.20450975525728676\n",
            "Train data MGD:  0.0043516445714956034\n",
            "Test data MGD:  0.0020703644588878634\n",
            "----------------------------------------------------------------------\n",
            "Train data MPD:  0.004245482831062096\n",
            "Test data MPD:  0.00206367850834108\n",
            "(716, 15, 191) (716,)\n",
            "Epoch 1/200\n",
            "18/18 [==============================] - 4s 65ms/step - loss: 1.5042 - accuracy: 0.0000e+00 - val_loss: 0.3421 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.6222 - accuracy: 0.0000e+00 - val_loss: 0.0660 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.2989 - accuracy: 0.0000e+00 - val_loss: 0.1095 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.2119 - accuracy: 0.0000e+00 - val_loss: 0.1422 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.2383 - accuracy: 0.0000e+00 - val_loss: 0.1426 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.2047 - accuracy: 0.0000e+00 - val_loss: 0.1205 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.1791 - accuracy: 0.0000e+00 - val_loss: 0.1023 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.1603 - accuracy: 0.0000e+00 - val_loss: 0.0983 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.1543 - accuracy: 0.0000e+00 - val_loss: 0.0967 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.1400 - accuracy: 0.0000e+00 - val_loss: 0.0893 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.1329 - accuracy: 0.0000e+00 - val_loss: 0.0822 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.1373 - accuracy: 0.0000e+00 - val_loss: 0.0896 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.1205 - accuracy: 0.0000e+00 - val_loss: 0.0882 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.1221 - accuracy: 0.0000e+00 - val_loss: 0.0694 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.1189 - accuracy: 0.0000e+00 - val_loss: 0.0656 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.1198 - accuracy: 0.0000e+00 - val_loss: 0.0647 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.1231 - accuracy: 0.0000e+00 - val_loss: 0.0638 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.1124 - accuracy: 0.0000e+00 - val_loss: 0.0599 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.1030 - accuracy: 0.0000e+00 - val_loss: 0.0503 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.1064 - accuracy: 0.0000e+00 - val_loss: 0.0545 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0857 - accuracy: 0.0000e+00 - val_loss: 0.0457 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0913 - accuracy: 0.0000e+00 - val_loss: 0.0410 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0909 - accuracy: 0.0000e+00 - val_loss: 0.0438 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0833 - accuracy: 0.0000e+00 - val_loss: 0.0356 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0817 - accuracy: 0.0000e+00 - val_loss: 0.0392 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0807 - accuracy: 0.0000e+00 - val_loss: 0.0351 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0832 - accuracy: 0.0000e+00 - val_loss: 0.0289 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0691 - accuracy: 0.0000e+00 - val_loss: 0.0269 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0679 - accuracy: 0.0000e+00 - val_loss: 0.0251 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0685 - accuracy: 0.0000e+00 - val_loss: 0.0253 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0650 - accuracy: 0.0000e+00 - val_loss: 0.0261 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0674 - accuracy: 0.0000e+00 - val_loss: 0.0231 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0651 - accuracy: 0.0000e+00 - val_loss: 0.0210 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0572 - accuracy: 0.0000e+00 - val_loss: 0.0219 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0674 - accuracy: 0.0000e+00 - val_loss: 0.0158 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0606 - accuracy: 0.0000e+00 - val_loss: 0.0154 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0635 - accuracy: 0.0000e+00 - val_loss: 0.0194 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0660 - accuracy: 0.0000e+00 - val_loss: 0.0174 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0604 - accuracy: 0.0000e+00 - val_loss: 0.0168 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0629 - accuracy: 0.0000e+00 - val_loss: 0.0150 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0592 - accuracy: 0.0000e+00 - val_loss: 0.0146 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0568 - accuracy: 0.0000e+00 - val_loss: 0.0149 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0582 - accuracy: 0.0000e+00 - val_loss: 0.0133 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0566 - accuracy: 0.0000e+00 - val_loss: 0.0134 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0539 - accuracy: 0.0000e+00 - val_loss: 0.0127 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0554 - accuracy: 0.0000e+00 - val_loss: 0.0111 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0574 - accuracy: 0.0000e+00 - val_loss: 0.0112 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0544 - accuracy: 0.0000e+00 - val_loss: 0.0098 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0538 - accuracy: 0.0000e+00 - val_loss: 0.0102 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0526 - accuracy: 0.0000e+00 - val_loss: 0.0084 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0524 - accuracy: 0.0000e+00 - val_loss: 0.0080 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0514 - accuracy: 0.0000e+00 - val_loss: 0.0084 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0496 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0461 - accuracy: 0.0000e+00 - val_loss: 0.0074 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0491 - accuracy: 0.0000e+00 - val_loss: 0.0073 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0447 - accuracy: 0.0000e+00 - val_loss: 0.0096 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0475 - accuracy: 0.0000e+00 - val_loss: 0.0083 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0481 - accuracy: 0.0000e+00 - val_loss: 0.0079 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0473 - accuracy: 0.0000e+00 - val_loss: 0.0096 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0450 - accuracy: 0.0000e+00 - val_loss: 0.0121 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0405 - accuracy: 0.0000e+00 - val_loss: 0.0077 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0499 - accuracy: 0.0000e+00 - val_loss: 0.0100 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0426 - accuracy: 0.0000e+00 - val_loss: 0.0080 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0449 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0444 - accuracy: 0.0000e+00 - val_loss: 0.0087 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0450 - accuracy: 0.0000e+00 - val_loss: 0.0076 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/200\n",
            "18/18 [==============================] - 1s 53ms/step - loss: 0.0444 - accuracy: 0.0000e+00 - val_loss: 0.0083 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0362 - accuracy: 0.0000e+00 - val_loss: 0.0066 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0424 - accuracy: 0.0000e+00 - val_loss: 0.0068 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0416 - accuracy: 0.0000e+00 - val_loss: 0.0065 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0453 - accuracy: 0.0000e+00 - val_loss: 0.0073 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0441 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0417 - accuracy: 0.0000e+00 - val_loss: 0.0068 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0439 - accuracy: 0.0000e+00 - val_loss: 0.0085 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0433 - accuracy: 0.0000e+00 - val_loss: 0.0095 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0434 - accuracy: 0.0000e+00 - val_loss: 0.0084 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0398 - accuracy: 0.0000e+00 - val_loss: 0.0078 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/200\n",
            "18/18 [==============================] - 1s 52ms/step - loss: 0.0417 - accuracy: 0.0000e+00 - val_loss: 0.0095 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0405 - accuracy: 0.0000e+00 - val_loss: 0.0087 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0415 - accuracy: 0.0000e+00 - val_loss: 0.0057 - val_accuracy: 0.0000e+00\n",
            "Epoch 81/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0407 - accuracy: 0.0000e+00 - val_loss: 0.0085 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0401 - accuracy: 0.0000e+00 - val_loss: 0.0078 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0423 - accuracy: 0.0000e+00 - val_loss: 0.0082 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0386 - accuracy: 0.0000e+00 - val_loss: 0.0074 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0426 - accuracy: 0.0000e+00 - val_loss: 0.0091 - val_accuracy: 0.0000e+00\n",
            "Epoch 86/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0394 - accuracy: 0.0000e+00 - val_loss: 0.0083 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0410 - accuracy: 0.0000e+00 - val_loss: 0.0073 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0393 - accuracy: 0.0000e+00 - val_loss: 0.0097 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0392 - accuracy: 0.0000e+00 - val_loss: 0.0073 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0398 - accuracy: 0.0000e+00 - val_loss: 0.0071 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0372 - accuracy: 0.0000e+00 - val_loss: 0.0092 - val_accuracy: 0.0000e+00\n",
            "Epoch 92/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0389 - accuracy: 0.0000e+00 - val_loss: 0.0093 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0381 - accuracy: 0.0000e+00 - val_loss: 0.0084 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0385 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0381 - accuracy: 0.0000e+00 - val_loss: 0.0072 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0385 - accuracy: 0.0000e+00 - val_loss: 0.0076 - val_accuracy: 0.0000e+00\n",
            "Epoch 97/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0389 - accuracy: 0.0000e+00 - val_loss: 0.0057 - val_accuracy: 0.0000e+00\n",
            "Epoch 98/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0393 - accuracy: 0.0000e+00 - val_loss: 0.0091 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0384 - accuracy: 0.0000e+00 - val_loss: 0.0084 - val_accuracy: 0.0000e+00\n",
            "Epoch 100/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0382 - accuracy: 0.0000e+00 - val_loss: 0.0064 - val_accuracy: 0.0000e+00\n",
            "Epoch 101/200\n",
            "18/18 [==============================] - 1s 53ms/step - loss: 0.0380 - accuracy: 0.0000e+00 - val_loss: 0.0068 - val_accuracy: 0.0000e+00\n",
            "Epoch 102/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0404 - accuracy: 0.0000e+00 - val_loss: 0.0070 - val_accuracy: 0.0000e+00\n",
            "Epoch 103/200\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0375 - accuracy: 0.0000e+00 - val_loss: 0.0067 - val_accuracy: 0.0000e+00\n",
            "Epoch 104/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0376 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
            "Epoch 105/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0418 - accuracy: 0.0000e+00 - val_loss: 0.0050 - val_accuracy: 0.0000e+00\n",
            "Epoch 106/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0361 - accuracy: 0.0000e+00 - val_loss: 0.0049 - val_accuracy: 0.0000e+00\n",
            "Epoch 107/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0368 - accuracy: 0.0000e+00 - val_loss: 0.0064 - val_accuracy: 0.0000e+00\n",
            "Epoch 108/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0384 - accuracy: 0.0000e+00 - val_loss: 0.0049 - val_accuracy: 0.0000e+00\n",
            "Epoch 109/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0380 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_accuracy: 0.0000e+00\n",
            "Epoch 110/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0385 - accuracy: 0.0000e+00 - val_loss: 0.0071 - val_accuracy: 0.0000e+00\n",
            "Epoch 111/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0383 - accuracy: 0.0000e+00 - val_loss: 0.0051 - val_accuracy: 0.0000e+00\n",
            "Epoch 112/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0373 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_accuracy: 0.0000e+00\n",
            "Epoch 113/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0368 - accuracy: 0.0000e+00 - val_loss: 0.0070 - val_accuracy: 0.0000e+00\n",
            "Epoch 114/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0378 - accuracy: 0.0000e+00 - val_loss: 0.0073 - val_accuracy: 0.0000e+00\n",
            "Epoch 115/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0351 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_accuracy: 0.0000e+00\n",
            "Epoch 116/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0353 - accuracy: 0.0000e+00 - val_loss: 0.0068 - val_accuracy: 0.0000e+00\n",
            "Epoch 117/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0366 - accuracy: 0.0000e+00 - val_loss: 0.0064 - val_accuracy: 0.0000e+00\n",
            "Epoch 118/200\n",
            "18/18 [==============================] - 1s 52ms/step - loss: 0.0359 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\n",
            "Epoch 119/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0369 - accuracy: 0.0000e+00 - val_loss: 0.0078 - val_accuracy: 0.0000e+00\n",
            "Epoch 120/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0382 - accuracy: 0.0000e+00 - val_loss: 0.0067 - val_accuracy: 0.0000e+00\n",
            "Epoch 121/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0386 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_accuracy: 0.0000e+00\n",
            "Epoch 122/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0364 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_accuracy: 0.0000e+00\n",
            "Epoch 123/200\n",
            "18/18 [==============================] - 1s 52ms/step - loss: 0.0370 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_accuracy: 0.0000e+00\n",
            "Epoch 124/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0372 - accuracy: 0.0000e+00 - val_loss: 0.0051 - val_accuracy: 0.0000e+00\n",
            "Epoch 125/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0366 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\n",
            "Epoch 126/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0349 - accuracy: 0.0000e+00 - val_loss: 0.0070 - val_accuracy: 0.0000e+00\n",
            "Epoch 127/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0346 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_accuracy: 0.0000e+00\n",
            "Epoch 128/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0362 - accuracy: 0.0000e+00 - val_loss: 0.0067 - val_accuracy: 0.0000e+00\n",
            "Epoch 129/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0366 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\n",
            "Epoch 130/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0370 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_accuracy: 0.0000e+00\n",
            "Epoch 131/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0356 - accuracy: 0.0000e+00 - val_loss: 0.0062 - val_accuracy: 0.0000e+00\n",
            "Epoch 132/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0358 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_accuracy: 0.0000e+00\n",
            "Epoch 133/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0366 - accuracy: 0.0000e+00 - val_loss: 0.0062 - val_accuracy: 0.0000e+00\n",
            "Epoch 134/200\n",
            "18/18 [==============================] - 1s 53ms/step - loss: 0.0350 - accuracy: 0.0000e+00 - val_loss: 0.0078 - val_accuracy: 0.0000e+00\n",
            "Epoch 135/200\n",
            "18/18 [==============================] - 1s 53ms/step - loss: 0.0345 - accuracy: 0.0000e+00 - val_loss: 0.0049 - val_accuracy: 0.0000e+00\n",
            "Epoch 136/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0350 - accuracy: 0.0000e+00 - val_loss: 0.0056 - val_accuracy: 0.0000e+00\n",
            "Epoch 137/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0363 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_accuracy: 0.0000e+00\n",
            "Epoch 138/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0347 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_accuracy: 0.0000e+00\n",
            "Epoch 139/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0362 - accuracy: 0.0000e+00 - val_loss: 0.0075 - val_accuracy: 0.0000e+00\n",
            "Epoch 140/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0358 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\n",
            "Epoch 141/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0352 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_accuracy: 0.0000e+00\n",
            "Epoch 142/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0353 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 143/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0360 - accuracy: 0.0000e+00 - val_loss: 0.0057 - val_accuracy: 0.0000e+00\n",
            "Epoch 144/200\n",
            "18/18 [==============================] - 1s 52ms/step - loss: 0.0361 - accuracy: 0.0000e+00 - val_loss: 0.0076 - val_accuracy: 0.0000e+00\n",
            "Epoch 145/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0363 - accuracy: 0.0000e+00 - val_loss: 0.0084 - val_accuracy: 0.0000e+00\n",
            "Epoch 146/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0355 - accuracy: 0.0000e+00 - val_loss: 0.0052 - val_accuracy: 0.0000e+00\n",
            "Epoch 147/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0343 - accuracy: 0.0000e+00 - val_loss: 0.0069 - val_accuracy: 0.0000e+00\n",
            "Epoch 148/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0340 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
            "Epoch 149/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0360 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\n",
            "Epoch 150/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0339 - accuracy: 0.0000e+00 - val_loss: 0.0056 - val_accuracy: 0.0000e+00\n",
            "Epoch 151/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0343 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\n",
            "Epoch 152/200\n",
            "18/18 [==============================] - 1s 52ms/step - loss: 0.0366 - accuracy: 0.0000e+00 - val_loss: 0.0079 - val_accuracy: 0.0000e+00\n",
            "Epoch 153/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0350 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
            "Epoch 154/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0388 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
            "Epoch 155/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0355 - accuracy: 0.0000e+00 - val_loss: 0.0052 - val_accuracy: 0.0000e+00\n",
            "Epoch 156/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0351 - accuracy: 0.0000e+00 - val_loss: 0.0060 - val_accuracy: 0.0000e+00\n",
            "Epoch 157/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0348 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\n",
            "Epoch 158/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0352 - accuracy: 0.0000e+00 - val_loss: 0.0077 - val_accuracy: 0.0000e+00\n",
            "Epoch 159/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0346 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_accuracy: 0.0000e+00\n",
            "Epoch 160/200\n",
            "18/18 [==============================] - 1s 53ms/step - loss: 0.0344 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
            "Epoch 161/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0351 - accuracy: 0.0000e+00 - val_loss: 0.0064 - val_accuracy: 0.0000e+00\n",
            "Epoch 162/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0356 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
            "Epoch 163/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0350 - accuracy: 0.0000e+00 - val_loss: 0.0081 - val_accuracy: 0.0000e+00\n",
            "Epoch 164/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0349 - accuracy: 0.0000e+00 - val_loss: 0.0087 - val_accuracy: 0.0000e+00\n",
            "Epoch 165/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0347 - accuracy: 0.0000e+00 - val_loss: 0.0074 - val_accuracy: 0.0000e+00\n",
            "Epoch 166/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0344 - accuracy: 0.0000e+00 - val_loss: 0.0078 - val_accuracy: 0.0000e+00\n",
            "Epoch 167/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0349 - accuracy: 0.0000e+00 - val_loss: 0.0076 - val_accuracy: 0.0000e+00\n",
            "Epoch 168/200\n",
            "18/18 [==============================] - 1s 53ms/step - loss: 0.0350 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_accuracy: 0.0000e+00\n",
            "Epoch 169/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0356 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
            "Epoch 170/200\n",
            "18/18 [==============================] - 1s 52ms/step - loss: 0.0353 - accuracy: 0.0000e+00 - val_loss: 0.0051 - val_accuracy: 0.0000e+00\n",
            "Epoch 171/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0344 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
            "Epoch 172/200\n",
            "18/18 [==============================] - 1s 52ms/step - loss: 0.0354 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\n",
            "Epoch 173/200\n",
            "18/18 [==============================] - 1s 52ms/step - loss: 0.0362 - accuracy: 0.0000e+00 - val_loss: 0.0067 - val_accuracy: 0.0000e+00\n",
            "Epoch 174/200\n",
            "18/18 [==============================] - 1s 53ms/step - loss: 0.0361 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
            "Epoch 175/200\n",
            "18/18 [==============================] - 1s 54ms/step - loss: 0.0354 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
            "Epoch 176/200\n",
            "18/18 [==============================] - 1s 53ms/step - loss: 0.0345 - accuracy: 0.0000e+00 - val_loss: 0.0051 - val_accuracy: 0.0000e+00\n",
            "Epoch 177/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0354 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_accuracy: 0.0000e+00\n",
            "Epoch 178/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0344 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\n",
            "Epoch 179/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0345 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\n",
            "Epoch 180/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0338 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
            "Epoch 181/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0339 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
            "Epoch 182/200\n",
            "18/18 [==============================] - 1s 53ms/step - loss: 0.0346 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
            "Epoch 183/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0331 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_accuracy: 0.0000e+00\n",
            "Epoch 184/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0346 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\n",
            "Epoch 185/200\n",
            "18/18 [==============================] - 1s 54ms/step - loss: 0.0346 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
            "Epoch 186/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0351 - accuracy: 0.0000e+00 - val_loss: 0.0082 - val_accuracy: 0.0000e+00\n",
            "Epoch 187/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0347 - accuracy: 0.0000e+00 - val_loss: 0.0070 - val_accuracy: 0.0000e+00\n",
            "Epoch 188/200\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.0354 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
            "Epoch 189/200\n",
            "18/18 [==============================] - 1s 53ms/step - loss: 0.0343 - accuracy: 0.0000e+00 - val_loss: 0.0051 - val_accuracy: 0.0000e+00\n",
            "Epoch 190/200\n",
            "18/18 [==============================] - 1s 53ms/step - loss: 0.0347 - accuracy: 0.0000e+00 - val_loss: 0.0069 - val_accuracy: 0.0000e+00\n",
            "Epoch 191/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0352 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
            "Epoch 192/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0335 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
            "Epoch 193/200\n",
            "18/18 [==============================] - 1s 52ms/step - loss: 0.0338 - accuracy: 0.0000e+00 - val_loss: 0.0062 - val_accuracy: 0.0000e+00\n",
            "Epoch 194/200\n",
            "18/18 [==============================] - 1s 54ms/step - loss: 0.0364 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
            "Epoch 195/200\n",
            "18/18 [==============================] - 1s 53ms/step - loss: 0.0348 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
            "Epoch 196/200\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.0338 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_accuracy: 0.0000e+00\n",
            "Epoch 197/200\n",
            "18/18 [==============================] - 1s 52ms/step - loss: 0.0341 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
            "Epoch 198/200\n",
            "18/18 [==============================] - 1s 53ms/step - loss: 0.0339 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
            "Epoch 199/200\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.0344 - accuracy: 0.0000e+00 - val_loss: 0.0049 - val_accuracy: 0.0000e+00\n",
            "Epoch 200/200\n",
            "18/18 [==============================] - 1s 52ms/step - loss: 0.0357 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(572,) (144,)\n",
            "Train data RMSE:  0.1796544212358706\n",
            "Train data MSE:  0.03227571106959563\n",
            "Train data MAE:  0.0648274213098243\n",
            "-------------------------------------------------------------------------------------\n",
            "Test data RMSE:  0.06654875638727588\n",
            "Test data MSE:  0.004428736976692993\n",
            "Test data MAE:  0.05432216156718415\n",
            "Train data R2 score: -0.008746870234653148\n",
            "Test data R2 score: -0.9392017304581413\n",
            "Train data MGD:  0.015910122992169644\n",
            "Test data MGD:  0.0042543385812151314\n",
            "----------------------------------------------------------------------\n",
            "Train data MPD:  0.02105248884506013\n",
            "Test data MPD:  0.0043368655045827225\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"LSTMPredictor.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1snuaWc20AeWGvnrBaj0MKyRIcmX3l6jS\n",
        "\"\"\"\n",
        "\n",
        "# !pip install ipdb\n",
        "# First we will import the necessary Library\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import datetime as dt\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "# For Evalution we will use these library\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, r2_score\n",
        "from sklearn.metrics import mean_poisson_deviance, mean_gamma_deviance, accuracy_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# For model building we will use these library\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "\n",
        "# For PLotting we will use these library\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import cycle\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/MyDrive')\n",
        "\n",
        "def main(filepath: str, filename: str, prediction_columns: list, time_step: int = 10, num_units: int = 128, batch_size: int = 32):\n",
        "\n",
        "    maindf = pd.read_csv(filename)\n",
        "\n",
        "    describe_dataframe(maindf)\n",
        "\n",
        "    maindf = preprocess_dataset(maindf)\n",
        "\n",
        "    # convert an array of values into a dataset matrix\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    columns = ['index', 'Date', 'BTC_Open', 'BTC_Close', 'BTC_Volume', 'BTC_change_factor', \n",
        "    'ETH_Open', 'ETH_Close', 'ETH_Volume', 'ETH_change_factor', 'DOGE_Open', 'DOGE_Close',\n",
        "    'DOGE_Volume', 'DOGE_change_factor', 'btc_newsPosScoreaverage', 'btc_newsNegScoreaverage',\n",
        "    'btc_newsComScoreaverage', 'btc_newsScorecount', 'eth_newsPosScoreaverage', \n",
        "    'eth_newsNegScoreaverage', 'eth_newsComScoreaverage', 'eth_newsScorecount', \n",
        "    'doge_newsPosScoreaverage', 'doge_newsNegScoreaverage', 'doge_newsComScoreaverage', \n",
        "    'doge_newsScorecount', 'cryptocurrency_newsPosScoreaverage', 'cryptocurrency_newsNegScoreaverage', \n",
        "    'cryptocurrency_newsComScoreaverage', 'cryptocurrency_newsScorecount', 'economy_newsPosScoreaverage', \n",
        "    'economy_newsNegScoreaverage', 'economy_newsComScoreaverage', 'economy_newsScorecount',\n",
        "    'finance_newsPosScoreaverage', 'finance_newsNegScoreaverage', 'finance_newsComScoreaverage', \n",
        "    'finance_newsScorecount', 'politics_newsPosScoreaverage', 'politics_newsNegScoreaverage', \n",
        "    'politics_newsComScoreaverage', 'politics_newsScorecount', 'pandemic_newsPosScoreaverage', \n",
        "    'pandemic_newsNegScoreaverage', 'pandemic_newsComScoreaverage', 'pandemic_newsScorecount', \n",
        "    'btc_redditPosScoreaverage', 'btc_redditNegScoreaverage', 'btc_redditComScoreaverage', \n",
        "    'btc_redditScorecount', 'eth_redditPosScoreaverage', 'eth_redditNegScoreaverage', \n",
        "    'eth_redditComScoreaverage', 'eth_redditScorecount', 'doge_redditPosScoreaverage', \n",
        "    'doge_redditNegScoreaverage', 'doge_redditComScoreaverage', 'doge_redditScorecount', \n",
        "    'cryptocurrency_redditPosScoreaverage', 'cryptocurrency_redditNegScoreaverage', \n",
        "    'cryptocurrency_redditComScoreaverage', 'cryptocurrency_redditScorecount', \n",
        "    'economy_redditPosScoreaverage', 'economy_redditNegScoreaverage', \n",
        "    'economy_redditComScoreaverage', 'economy_redditScorecount', 'finance_redditPosScoreaverage', \n",
        "    'finance_redditNegScoreaverage', 'finance_redditComScoreaverage', 'finance_redditScorecount', \n",
        "    'politics_redditPosScoreaverage', 'politics_redditNegScoreaverage', 'politics_redditComScoreaverage', \n",
        "    'politics_redditScorecount', 'pandemic_redditPosScoreaverage', 'pandemic_redditNegScoreaverage', \n",
        "    'pandemic_redditComScoreaverage', 'pandemic_redditScorecount']\n",
        "    \"\"\"\n",
        "    columns = list(maindf.columns)[1:]\n",
        "\n",
        "    for prediction_column in prediction_columns:\n",
        "        X, y = create_dataset(maindf, columns, prediction_column, time_step)\n",
        "        print(np.shape(X), np.shape(y))\n",
        "        X_train, X_test, y_train, y_test = traintest_split(X, y)\n",
        "\n",
        "        input_shape = (None, len(X[0][0]))\n",
        "\n",
        "        # model.add(LSTM(128, \"relu\", dropout=.2, recurrent_dropout=0.2, input_shape=(None, len(X_train[0][0])))\n",
        "        # model.add(LSTM(time_step, input_dim=len(X_train[0][0]), activation=\"relu\"))\n",
        "\n",
        "        \"\"\"\n",
        "        units, activation='tanh', recurrent_activation='sigmoid', use_bias=True, \n",
        "        kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', \n",
        "        bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, \n",
        "        recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, \n",
        "        kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, \n",
        "        dropout=0.0, recurrent_dropout=0.0, return_sequences=False, return_state=False, \n",
        "        go_backwards=False, stateful=False,\n",
        "        \"\"\"\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(LSTM(num_units, dropout=0.2, recurrent_dropout=0.2, input_shape=input_shape))\n",
        "        model.add(Dense(1))\n",
        "\n",
        "        model.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[tf.keras.metrics.Accuracy()])\n",
        "        history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=200, batch_size=batch_size,\n",
        "                              verbose=1)\n",
        "        \n",
        "        loss = history.history['loss']\n",
        "        val_loss = history.history['val_loss']\n",
        "\n",
        "        epochs = range(len(loss))\n",
        "\n",
        "        plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "        plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "        plt.title('Training and validation loss')\n",
        "        plt.legend(loc=0)\n",
        "        plt.figure()\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "        pad = np.zeros(time_step-1)\n",
        "\n",
        "        train_predict1 = model.predict(X_train).reshape(len(X_train))\n",
        "        test_predict1 = model.predict(X_test).reshape(len(X_test))\n",
        "        print(train_predict1.shape, test_predict1.shape)\n",
        "        pred = np.concatenate((pad, train_predict1, test_predict1), axis=None)\n",
        "        maindf[prediction_column+\"-prediction\"] = pd.DataFrame(pred) \n",
        "\n",
        "        maindf.to_csv(filename, index = False)\n",
        "        \n",
        "        # Evaluation metrices RMSE and MAE\n",
        "        print(\"Train data RMSE: \", math.sqrt(mean_squared_error(y_train, train_predict1)))\n",
        "        print(\"Train data MSE: \", mean_squared_error(y_train, train_predict1))\n",
        "        print(\"Train data MAE: \", mean_absolute_error(y_train, train_predict1))\n",
        "        print(\"-------------------------------------------------------------------------------------\")\n",
        "        print(\"Test data RMSE: \", math.sqrt(mean_squared_error(y_test, test_predict1)))\n",
        "        print(\"Test data MSE: \", mean_squared_error(y_test, test_predict1))\n",
        "        print(\"Test data MAE: \", mean_absolute_error(y_test, test_predict1))\n",
        "\n",
        "        \"\"\"- ## Variance Regression Score\"\"\"\n",
        "        # print(\"Train data explained variance regression score:\",\n",
        "              # explained_variance_score(y, pred[20:]))\n",
        "\n",
        "        \"\"\"- ## R square score for regression\"\"\"\n",
        "\n",
        "        print(\"Train data R2 score:\", r2_score(y_train, train_predict1))\n",
        "        print(\"Test data R2 score:\", r2_score(y_test, test_predict1))\n",
        "\n",
        "        \"\"\"- ## Regression Loss Mean Gamma deviance regression loss (MGD) and Mean Poisson deviance regression loss (MPD)\"\"\"\n",
        "\n",
        "        print(\"Train data MGD: \", mean_gamma_deviance(y_train, train_predict1))\n",
        "        print(\"Test data MGD: \", mean_gamma_deviance(y_test, test_predict1))\n",
        "        print(\"----------------------------------------------------------------------\")\n",
        "        print(\"Train data MPD: \", mean_poisson_deviance(y_train, train_predict1))\n",
        "        print(\"Test data MPD: \", mean_poisson_deviance(y_test, test_predict1))\n",
        "\n",
        "    return True\n",
        "\n",
        "def traintest_split(X: np.array, y: np.array, split: float = 0.8):\n",
        "    train_size = int(split*len(X))\n",
        "    X_train = X[:train_size]\n",
        "    X_test = X[train_size:]\n",
        "\n",
        "    y_train = y[:train_size]\n",
        "    y_test = y[train_size:]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "def preprocess_dataset(df):\n",
        "    df.replace(to_replace=np.nan, value=0.0, inplace=True)\n",
        "    print(df.shape)\n",
        "    # normalize_dataset(df)\n",
        "    return df\n",
        "\n",
        "def create_dataset(dataset: pd.DataFrame, columns_X: list, column_Y: str, time_step=1):\n",
        "\n",
        "    # create x and y datasets, to be passed into model\n",
        "    # \n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset) - time_step - 1):\n",
        "        # The daily subset ranges from the index up until index + timestep -1\n",
        "          # Becaus\n",
        "        daily_subset = dataset.loc[i:(i + time_step - 1), columns_X]\n",
        "        dataX.append(daily_subset)\n",
        "        dataY.append(dataset.loc[i + time_step, column_Y])\n",
        "    return np.array(dataX), np.array(dataY)\n",
        "\n",
        "def normalize_dataset(data: pd.DataFrame):\n",
        "    columns = list(data.columns)\n",
        "    for column in columns[1:]:\n",
        "        data[column] = normalize_column(data[column])\n",
        "\n",
        "def normalize_column(column: pd.Series) -> pd.Series:\n",
        "    STD = np.std(column)\n",
        "    mean = np.mean(column)\n",
        "    column = column.apply(lambda x: (x - mean) / STD)\n",
        "    return column\n",
        "\n",
        "def describe_dataframe(df: pd.DataFrame):\n",
        "    print(df)\n",
        "\n",
        "    print('Total number of days present in the dataset: ', df.shape[0])\n",
        "    print('Total number of fields present in the dataset: ', df.shape[1])\n",
        "\n",
        "    print(df.shape,\n",
        "\n",
        "    df.head(),\n",
        "\n",
        "    df.tail(),\n",
        "\n",
        "    df.info(),\n",
        "\n",
        "    df.describe(),\n",
        "\n",
        "    df.columns)\n",
        "\n",
        "    print('\\n\\n\\nNull Values:', df.isnull().values.sum())\n",
        "\n",
        "    print('\\n\\n\\nNA values:', df.isnull().values.any(), \"\\n\\n\\n\")\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "\n",
        "    # script, filepath, currencies = sys.argv\n",
        "    # currencies = currencies.split()\n",
        "    filename = '/content/MyDrive/MyDrive/ISEF/Datasets/MergedPriceDataEMA7.csv'\n",
        "    filepath = '/content/MyDrive/MyDrive/ISEF/Datasets'\n",
        "    # drive.mount('/content/MyDrive')\n",
        "\n",
        "    # filepath = './'\n",
        "    # filename = './MergedPriceDataEMA.csv'\n",
        "    prediction_columns = [\n",
        "        'BTC-ChangeFactor-EMA7',\n",
        "        'ETH-ChangeFactor-EMA7',\n",
        "        'DOGE-ChangeFactor-EMA7',\n",
        "        'BTC-ChangeFactor',\n",
        "        'ETH-ChangeFactor',\n",
        "        'DOGE-ChangeFactor'\n",
        "    ]\n",
        "\n",
        "    main(filepath, filename, prediction_columns, time_step = 15)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = [1, 2, 3, 4, 5]\n",
        "a[1:3]"
      ],
      "metadata": {
        "id": "cGPomIWaJTk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SKvVUUnLj6iu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "LSTM_Updated.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMUt/MTYLDCxXdVLeVNaBCz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}