{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Merging Dates",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XGHouFTW/py-cryptopredict/blob/main/Merging_Dates.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAWhuU117uvs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import datetime\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "basepath = \"/content/drive/MyDrive/ISEF/Datasets/Stonks/Preprocessed/CryptoStockPrice.csv\"\n",
        "dfbase = pd.read_csv(basepath)\n",
        "\n",
        "medium = {\"news\":\"/content/drive/MyDrive/ISEF/Datasets/Google News/\",\"reddit\":\"/content/drive/MyDrive/ISEF/Datasets/Reddit/Reddit V3/Reformatted Dates/\"}\n",
        "keyword = [\"bitcoin\",\"ethereum\",\"dogecoin\",\"cryptocurrency\",\"economy\",\"finance\",\"politics\",\"pandemic\"]\n",
        "scorelist = {} #dictionary of scorecolumnname and path\n",
        "for med in medium:\n",
        "  for word in keyword:\n",
        "    scorelist[med + \"-\" + word] = medium[med] + med + \"-\" + word + \"-scored.csv\""
      ],
      "metadata": {
        "id": "u2Ek0wfYKd-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transMonth = {\"Jan\":\"01\",\"Feb\":\"02\",\"Mar\":\"03\",\"Apr\":\"04\",\"May\":\"05\",\"Jun\":\"06\",\"Jul\":\"07\",\"Aug\":\"08\",\"Sep\":\"09\",\"Oct\":\"10\",\"Nov\":\"11\",\"Dec\":\"12\"}\n",
        "\n",
        "a = \"2020-01-31\t\" #from historical prices\n",
        "def trans(strdate):\n",
        "    return datetime.datetime(int(strdate[0:4]), int(strdate[5:7]), int(strdate[8:10]))"
      ],
      "metadata": {
        "id": "gu_DN5RVHfvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = trans(\"2020-01-31\") #to be compared to new dates for indexing\n",
        "for i in range(len(dfbase)):\n",
        "  dfbase.loc[i,\"Date\"] = trans(dfbase.loc[i,\"Date\"])"
      ],
      "metadata": {
        "id": "LFeW2tULDn6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for scoreset in scorelist:\n",
        "  dfAdd = pd.read_csv(scorelist[scoreset])\n",
        "\n",
        "  #initialize new columns with default value 0\n",
        "  dfbase[scoreset + \"PosScoresum\"] = 0\n",
        "  dfbase[scoreset + \"PosScoreaverage\"] = 0\n",
        "  dfbase[scoreset + \"NegScoresum\"] = 0\n",
        "  dfbase[scoreset + \"NegScoreaverage\"] = 0\n",
        "  dfbase[scoreset + \"ComScoresum\"] = 0\n",
        "  dfbase[scoreset + \"ComScoreaverage\"] = 0\n",
        "  dfbase[scoreset + \"Scorecount\"] = 0\n",
        "\n",
        "  for i in range(len(dfAdd)):\n",
        "    ind = (trans(dfAdd.loc[i,\"Date\"])-start).days #days since start of timeframe\n",
        "    if ind < 0 or ind > 731: #remove extraneous entries in dataset\n",
        "      print(\"Date out of range error:\" + scoreset + str(i) + dfAdd.loc[i,\"Date\"])\n",
        "    else:\n",
        "      dfbase.loc[ind, scoreset + \"PosScoresum\"] = dfbase.loc[ind, scoreset + \"PosScoresum\"] + dfAdd.loc[i,\"Pos\"] \n",
        "      dfbase.loc[ind, scoreset + \"NegScoresum\"] = dfbase.loc[ind, scoreset + \"NegScoresum\"] + dfAdd.loc[i,\"Neg\"] \n",
        "      dfbase.loc[ind, scoreset + \"ComScoresum\"] = dfbase.loc[ind, scoreset + \"ComScoresum\"] + dfAdd.loc[i,\"Com\"] \n",
        "      dfbase.loc[ind, scoreset + \"Scorecount\"] = dfbase.loc[ind, scoreset + \"Scorecount\"] + 1\n",
        "  \n",
        "  for i in range(len(dfbase)): #compute averages, if entry exists on this date\n",
        "    if not dfbase.loc[i,scoreset + \"Scorecount\"] == 0:\n",
        "      dfbase[scoreset + \"PosScoreaverage\"] = dfbase[scoreset + \"PosScoresum\"]/dfbase[scoreset + \"Scorecount\"]\n",
        "      dfbase[scoreset + \"NegScoreaverage\"] = dfbase[scoreset + \"NegScoresum\"]/dfbase[scoreset + \"Scorecount\"]\n",
        "      dfbase[scoreset + \"ComScoreaverage\"] = dfbase[scoreset + \"ComScoresum\"]/dfbase[scoreset + \"Scorecount\"]\n"
      ],
      "metadata": {
        "id": "HCOGZiIdJGOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfbase.to_csv(\"/content/drive/MyDrive/ISEF/Datasets/MergedPriceData.csv\", index=False)"
      ],
      "metadata": {
        "id": "tOJjDUvkUgvr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}